{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, LeakyReLU\n",
    "from torch_geometric.utils import scatter\n",
    "from torch_geometric.nn import MetaLayer\n",
    "\n",
    "class GlobalModel(torch.nn.Module):\n",
    "    def __init__(self, nf, gf, num_nodes, hidden_dim, output_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.global_mlp = Seq(Lin(gf + nf, hidden_dim),\n",
    "                              LeakyReLU(), \n",
    "                              nn.Dropout(p=dropout),\n",
    "                              Lin(hidden_dim, hidden_dim),\n",
    "                              LeakyReLU(),\n",
    "                              nn.Dropout(p=dropout),\n",
    "                              Lin(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        # x: [N, F_x], where N is the number of nodes.\n",
    "        # edge_index: [2, E] with max entry N - 1.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u]\n",
    "        # batch: [N] with max entry B - 1.\n",
    "        out = torch.cat([\n",
    "            u,\n",
    "            x.mean(dim=0).view(u.shape[0], -1),\n",
    "        ], dim=1)\n",
    "        return self.global_mlp(out)\n",
    "\n",
    "class EdgeModel(torch.nn.Module):\n",
    "    def __init__(self, nf, ef, gf, hidden_dim, output_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.edge_mlp = Seq(Lin(nf * 2 + ef + output_dim + 2, hidden_dim),\n",
    "                            LeakyReLU(),\n",
    "                            nn.Dropout(p=dropout),\n",
    "                            Lin(hidden_dim, hidden_dim),\n",
    "                            LeakyReLU(),\n",
    "                            nn.Dropout(p=dropout),\n",
    "                            Lin(hidden_dim, ef))\n",
    "\n",
    "    def forward(self, src, dest, edge_index, edge_attr, u, batch):\n",
    "        # src, dest: [E, F_x], where E is the number of edges.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u], where B is the number of graphs.\n",
    "        # batch: [E] with max entry B - 1.\n",
    "        out = torch.cat([src, dest, edge_index.t(), edge_attr, u.expand(src.shape[0], -1)], 1)\n",
    "        return self.edge_mlp(out)\n",
    "\n",
    "class NodeModel(torch.nn.Module):\n",
    "    def __init__(self, nf, ef, gf, hidden_dim, output_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.node_mlp_1 = Seq(Lin(nf + ef + 1, hidden_dim), \n",
    "                              ReLU(), \n",
    "                              nn.Dropout(p=dropout),\n",
    "                              Lin(hidden_dim, hidden_dim)\n",
    "                             )\n",
    "        self.node_mlp_2 = Seq(Lin(nf + hidden_dim + output_dim, hidden_dim),\n",
    "                              LeakyReLU(),\n",
    "                              nn.Dropout(p=dropout),\n",
    "                              Lin(hidden_dim, hidden_dim),\n",
    "                              LeakyReLU(),\n",
    "                              nn.Dropout(p=dropout),\n",
    "                              Lin(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        # x: [N, F_x], where N is the number of nodes.\n",
    "        # edge_index: [2, E] with max entry N - 1.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u]\n",
    "        # batch: [N] with max entry B - 1.\n",
    "        row, col = edge_index\n",
    "        out1 = torch.cat([x[row], row.view(-1, 1), edge_attr], dim=1)\n",
    "        out2 = torch.cat([x[col], col.view(-1, 1), edge_attr], dim=1)\n",
    "        \n",
    "        out1 = self.node_mlp_1(out1)\n",
    "        out2 = self.node_mlp_1(out2)\n",
    "        \n",
    "        out1 = scatter(out1, col, dim=0, dim_size=x.size(0), reduce='sum')\n",
    "        out2 = scatter(out2, row, dim=0, dim_size=x.size(0), reduce='sum')\n",
    "        out = out1 + out2 \n",
    "        \n",
    "        out = out / torch.norm(out, p=2)\n",
    "        \n",
    "        out = torch.cat([x, out, u.expand(x.shape[0], -1)], dim=1)\n",
    "        return self.node_mlp_2(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "class MetaLayer(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        edge_model: Optional[torch.nn.Module] = None,\n",
    "        node_model: Optional[torch.nn.Module] = None,\n",
    "        global_model: Optional[torch.nn.Module] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.edge_model = edge_model\n",
    "        self.node_model = node_model\n",
    "        self.global_model = global_model\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        for item in [self.node_model, self.edge_model, self.global_model]:\n",
    "            if hasattr(item, 'reset_parameters'):\n",
    "                item.reset_parameters()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        edge_index: Tensor,\n",
    "        edge_attr: Optional[Tensor] = None,\n",
    "        u: Optional[Tensor] = None,\n",
    "        batch: Optional[Tensor] = None,\n",
    "    ) -> Tuple[Tensor, Optional[Tensor], Optional[Tensor]]:\n",
    "        \n",
    "        row = edge_index[0]\n",
    "        col = edge_index[1]\n",
    "\n",
    "        if self.global_model is not None:\n",
    "            u = self.global_model(x, edge_index, edge_attr, u, batch)\n",
    "        \n",
    "        if self.edge_model is not None:\n",
    "            edge_attr = self.edge_model(x[row], x[col], edge_index, edge_attr, u,\n",
    "                                        batch if batch is None else batch[row])\n",
    "\n",
    "        if self.node_model is not None:\n",
    "            x = self.node_model(x, edge_index, edge_attr, u, batch)\n",
    "\n",
    "        return x, edge_attr, u\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(\\n'\n",
    "                f'  edge_model={self.edge_model},\\n'\n",
    "                f'  node_model={self.node_model},\\n'\n",
    "                f'  global_model={self.global_model}\\n'\n",
    "                f')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential, ReLU, Dropout, LeakyReLU\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "def meta_layer(nf, ef, gf, num_nodes, hidden_dim, output_dim, dropout=0.1):\n",
    "    edge_model = EdgeModel(nf, ef, gf, hidden_dim, output_dim, dropout=dropout)\n",
    "    node_model = NodeModel(nf, ef, gf, hidden_dim, output_dim, dropout=dropout)\n",
    "    global_model = GlobalModel(nf, gf, num_nodes, hidden_dim, output_dim, dropout=dropout)\n",
    "    return MetaLayer(\n",
    "        edge_model=edge_model,\n",
    "        node_model=node_model,\n",
    "        global_model=global_model)\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = Seq(Lin(latent_dim * 2, 32), LeakyReLU(), Lin(32, 1))\n",
    "        \n",
    "    def forward(self, h, s):\n",
    "        return F.sigmoid(self.disc(torch.cat([h, s])))\n",
    "    \n",
    "class VGAE(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, nf, ef, gf, hidden_dim, h_len=8, dropout_rate=0.1, l2_regularization=0.01):\n",
    "        super(VGAE, self).__init__()\n",
    "        \n",
    "        self.edge_index = torch.triu(torch.ones((input_dim, input_dim)), diagonal=1).nonzero(as_tuple=False).t()\n",
    "        \n",
    "        self.meta_encode_1 = GCNConv(nf, h_len)\n",
    "        self.disc = Discriminator(latent_dim)\n",
    "        \n",
    "        self.dropout = Dropout(p=dropout_rate)\n",
    "        self.l2_regularization = l2_regularization\n",
    "\n",
    "    def encode(self, x, edge_attr, u):\n",
    "        hs = F.leaky_relu(self.meta_encode_1(x, self.edge_index, edge_weight=edge_attr))\n",
    "        return hs, self.readout(hs)\n",
    "\n",
    "    def forward(self, x, edge_attr, u):\n",
    "        return self.encode(x, edge_attr, u)\n",
    "\n",
    "    def readout(self, hs):\n",
    "        return F.sigmoid(torch.mean(hs, 0))\n",
    "    \n",
    "    def loss_function(self, hs_0, hs_1, s_0, s_1):\n",
    "        e0 = 0.\n",
    "        e1 = 0.\n",
    "        \n",
    "        for h in hs_0:\n",
    "            e0 += torch.log(self.disc(h, s_0))\n",
    "        \n",
    "        for h in hs_1:\n",
    "            e1 += torch.log(1 - self.disc(h, s_0))\n",
    "        \n",
    "        obj_loss = e0 + e1\n",
    "\n",
    "        obj_loss = obj_loss / (hs_0.shape[0] + hs_1.shape[0])\n",
    "        # L2 regularization\n",
    "#         l2_loss = 0.\n",
    "#         for param in model.parameters():\n",
    "#             l2_loss += torch.norm(param, p=2) ** 2\n",
    "        return -obj_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "VGAE(\n",
      "  (meta_encode_1): GCNConv(1, 30)\n",
      "  (disc): Discriminator(\n",
      "    (disc): Sequential(\n",
      "      (0): Linear(in_features=60, out_features=32, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# set the random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# define the hyperparameters\n",
    "input_dim = 100  # size of the graph adjacency matrix\n",
    "latent_dim = 2\n",
    "lr = 1e-3\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils import BrainGraphDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from utils import BrainGraphDataset, get_data_labels\n",
    "import os\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "annotations = 'annotations.csv'\n",
    "dataroot = 'fc_matrices/hcp_100_ica/'\n",
    "cwd = os.getcwd() + '/'\n",
    "\n",
    "categories = ['patient_n','condition','bdi_before']\n",
    "\n",
    "batch_graph_size = 2\n",
    "\n",
    "data_labels = get_data_labels()\n",
    "data_labels = data_labels[categories]\n",
    "\n",
    "data_labels.loc[data_labels[\"condition\"] == \"P\", \"condition\"] = 1\n",
    "data_labels.loc[data_labels[\"condition\"] == \"E\", \"condition\"] = -1\n",
    "data_labels['condition'] = data_labels['condition'].astype('float64')\n",
    "\n",
    "dataset = BrainGraphDataset(img_dir=cwd + dataroot,\n",
    "                            annotations_file=cwd + dataroot + annotations,\n",
    "                            transform=None, extra_data=data_labels, setting='lz')\n",
    "\n",
    "dataroot = 'fc_matrices/psilo_ica_100_before/'\n",
    "psilo_dataset = BrainGraphDataset(img_dir=cwd + dataroot,\n",
    "                            annotations_file=cwd + annotations,\n",
    "                            transform=None, extra_data=None, setting='lz')\n",
    "\n",
    "psilo_train_loader = DataLoader(psilo_dataset, batch_size=batch_graph_size)\n",
    "\n",
    "# define the data loaders\n",
    "train_loader = DataLoader(dataset, batch_size=batch_graph_size, shuffle=True)\n",
    "val_loader = psilo_train_loader\n",
    "\n",
    "best_val_loss = float('inf')  # set to infinity to start\n",
    "best_model_state = None\n",
    "\n",
    "# define a dictionary to store the loss curves for each configuration\n",
    "loss_curves = {}\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "nf = 1\n",
    "ef = 1\n",
    "gf = 2\n",
    "\n",
    "hidden_dim = 32\n",
    "\n",
    "model = VGAE(100, nf, ef, gf, hidden_dim, latent_dim, dropout_rate=0).to(device)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        torch.nn.init.xavier_uniform_(param)\n",
    "\n",
    "print(model)        \n",
    "        \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5200, 0.5741, 0.4995, 0.4994, 0.4997, 0.4993, 0.5490, 0.5109, 0.4996,\n",
      "        0.4999, 0.5000, 0.5968, 0.6007, 0.4991, 0.5418, 0.5441, 0.5436, 0.4998,\n",
      "        0.5286, 0.5288, 0.6095, 0.4989, 0.4996, 0.4992, 0.4994, 0.5224, 0.5693,\n",
      "        0.4991, 0.5739, 0.5944], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5197, 0.5729, 0.4995, 0.4994, 0.4997, 0.4993, 0.5482, 0.5107, 0.4996,\n",
      "        0.4999, 0.5000, 0.5952, 0.5990, 0.4991, 0.5411, 0.5433, 0.5429, 0.4998,\n",
      "        0.5281, 0.5283, 0.6077, 0.4989, 0.4996, 0.4992, 0.4995, 0.5221, 0.5682,\n",
      "        0.4991, 0.5726, 0.5928], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5286, 0.5665, 0.4996, 0.4994, 0.4996, 0.4992, 0.5386, 0.5000, 0.4997,\n",
      "        0.5000, 0.5048, 0.5848, 0.5953, 0.4992, 0.5306, 0.5349, 0.5491, 0.4999,\n",
      "        0.5383, 0.5364, 0.6104, 0.4989, 0.4995, 0.4993, 0.4995, 0.5313, 0.5773,\n",
      "        0.4993, 0.5614, 0.5962], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5290, 0.5677, 0.4996, 0.4994, 0.4996, 0.4992, 0.5394, 0.5000, 0.4997,\n",
      "        0.5000, 0.5048, 0.5863, 0.5969, 0.4991, 0.5312, 0.5356, 0.5499, 0.4999,\n",
      "        0.5388, 0.5370, 0.6122, 0.4989, 0.4995, 0.4993, 0.4995, 0.5318, 0.5785,\n",
      "        0.4992, 0.5626, 0.5978], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5289, 0.5679, 0.4996, 0.4994, 0.4996, 0.4992, 0.5395, 0.5000, 0.4997,\n",
      "        0.5000, 0.5048, 0.5865, 0.5970, 0.4991, 0.5313, 0.5356, 0.5500, 0.4999,\n",
      "        0.5388, 0.5370, 0.6123, 0.4989, 0.4995, 0.4993, 0.4995, 0.5318, 0.5786,\n",
      "        0.4992, 0.5626, 0.5979], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5287, 0.5674, 0.4996, 0.4994, 0.4996, 0.4992, 0.5391, 0.5000, 0.4997,\n",
      "        0.5000, 0.5048, 0.5859, 0.5963, 0.4991, 0.5310, 0.5353, 0.5497, 0.4999,\n",
      "        0.5386, 0.5367, 0.6116, 0.4989, 0.4995, 0.4993, 0.4995, 0.5316, 0.5781,\n",
      "        0.4992, 0.5621, 0.5972], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5291, 0.5693, 0.4996, 0.4994, 0.4996, 0.4992, 0.5402, 0.5000, 0.4997,\n",
      "        0.5000, 0.5047, 0.5881, 0.5983, 0.4991, 0.5319, 0.5361, 0.5507, 0.4999,\n",
      "        0.5392, 0.5374, 0.6139, 0.4988, 0.4995, 0.4993, 0.4995, 0.5322, 0.5798,\n",
      "        0.4992, 0.5635, 0.5994], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5287, 0.5681, 0.4996, 0.4994, 0.4996, 0.4992, 0.5395, 0.5000, 0.4997,\n",
      "        0.5000, 0.5047, 0.5866, 0.5967, 0.4991, 0.5313, 0.5354, 0.5499, 0.4999,\n",
      "        0.5386, 0.5368, 0.6121, 0.4989, 0.4995, 0.4993, 0.4995, 0.5318, 0.5785,\n",
      "        0.4992, 0.5624, 0.5978], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5288, 0.5672, 0.4996, 0.4994, 0.4996, 0.4992, 0.5390, 0.5000, 0.4997,\n",
      "        0.5000, 0.5048, 0.5856, 0.5960, 0.4991, 0.5308, 0.5352, 0.5492, 0.4999,\n",
      "        0.5385, 0.5367, 0.6112, 0.4989, 0.4995, 0.4993, 0.4995, 0.5316, 0.5778,\n",
      "        0.4992, 0.5619, 0.5969], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5293, 0.5685, 0.4996, 0.4994, 0.4996, 0.4992, 0.5398, 0.5000, 0.4997,\n",
      "        0.5000, 0.5049, 0.5872, 0.5977, 0.4991, 0.5315, 0.5360, 0.5501, 0.4999,\n",
      "        0.5391, 0.5373, 0.6132, 0.4988, 0.4995, 0.4993, 0.4995, 0.5321, 0.5792,\n",
      "        0.4992, 0.5631, 0.5986], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:25<16:42, 25.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5293, 0.5672, 0.4996, 0.4994, 0.4996, 0.4992, 0.5391, 0.5000, 0.4997,\n",
      "        0.5000, 0.5050, 0.5858, 0.5967, 0.4991, 0.5309, 0.5357, 0.5494, 0.4999,\n",
      "        0.5389, 0.5371, 0.6120, 0.4989, 0.4995, 0.4993, 0.4995, 0.5318, 0.5782,\n",
      "        0.4992, 0.5624, 0.5973], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5290, 0.5663, 0.4996, 0.4994, 0.4996, 0.4992, 0.5385, 0.5000, 0.4997,\n",
      "        0.5000, 0.5050, 0.5846, 0.5955, 0.4992, 0.5304, 0.5352, 0.5488, 0.4999,\n",
      "        0.5385, 0.5366, 0.6107, 0.4989, 0.4995, 0.4993, 0.4995, 0.5315, 0.5773,\n",
      "        0.4993, 0.5615, 0.5962], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 1/40 - Train Loss: 0.3474 - Val Loss: 0.0000\n",
      "\n",
      "tensor([0.5296, 0.5679, 0.4996, 0.4994, 0.4996, 0.4992, 0.5395, 0.5000, 0.4997,\n",
      "        0.5000, 0.5050, 0.5867, 0.5978, 0.4991, 0.5313, 0.5361, 0.5498, 0.4999,\n",
      "        0.5393, 0.5374, 0.6132, 0.4988, 0.4995, 0.4993, 0.4995, 0.5321, 0.5790,\n",
      "        0.4992, 0.5631, 0.5983], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5294, 0.5675, 0.4996, 0.4994, 0.4996, 0.4992, 0.5393, 0.5000, 0.4997,\n",
      "        0.5000, 0.5050, 0.5862, 0.5972, 0.4991, 0.5311, 0.5359, 0.5496, 0.4999,\n",
      "        0.5391, 0.5372, 0.6125, 0.4989, 0.4995, 0.4993, 0.4995, 0.5319, 0.5785,\n",
      "        0.4992, 0.5627, 0.5978], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5298, 0.5671, 0.4996, 0.4994, 0.4996, 0.4992, 0.5391, 0.5000, 0.4997,\n",
      "        0.5000, 0.5051, 0.5858, 0.5970, 0.4991, 0.5308, 0.5359, 0.5492, 0.4999,\n",
      "        0.5392, 0.5373, 0.6123, 0.4989, 0.4995, 0.4993, 0.4995, 0.5319, 0.5783,\n",
      "        0.4992, 0.5626, 0.5975], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5297, 0.5668, 0.4996, 0.4994, 0.4996, 0.4992, 0.5389, 0.5000, 0.4997,\n",
      "        0.5000, 0.5051, 0.5854, 0.5966, 0.4991, 0.5307, 0.5357, 0.5490, 0.4999,\n",
      "        0.5391, 0.5371, 0.6119, 0.4989, 0.4995, 0.4993, 0.4995, 0.5318, 0.5780,\n",
      "        0.4992, 0.5623, 0.5972], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5308, 0.5692, 0.4996, 0.4994, 0.4996, 0.4992, 0.5404, 0.5000, 0.4997,\n",
      "        0.5000, 0.5053, 0.5885, 0.6004, 0.4991, 0.5319, 0.5374, 0.5506, 0.4999,\n",
      "        0.5405, 0.5385, 0.6160, 0.4988, 0.4995, 0.4993, 0.4995, 0.5329, 0.5806,\n",
      "        0.4992, 0.5649, 0.6005], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5304, 0.5681, 0.4996, 0.4994, 0.4996, 0.4992, 0.5398, 0.5000, 0.4997,\n",
      "        0.5000, 0.5053, 0.5871, 0.5990, 0.4991, 0.5314, 0.5368, 0.5499, 0.4999,\n",
      "        0.5399, 0.5380, 0.6144, 0.4988, 0.4995, 0.4993, 0.4995, 0.5324, 0.5795,\n",
      "        0.4992, 0.5639, 0.5991], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5313, 0.5673, 0.4996, 0.4994, 0.4996, 0.4992, 0.5393, 0.5000, 0.4997,\n",
      "        0.5000, 0.5057, 0.5861, 0.5990, 0.4991, 0.5309, 0.5370, 0.5494, 0.5000,\n",
      "        0.5403, 0.5384, 0.6141, 0.4988, 0.4995, 0.4993, 0.4995, 0.5325, 0.5792,\n",
      "        0.4992, 0.5640, 0.5985], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5313, 0.5673, 0.4996, 0.4994, 0.4996, 0.4992, 0.5393, 0.5000, 0.4997,\n",
      "        0.5000, 0.5057, 0.5860, 0.5989, 0.4991, 0.5309, 0.5370, 0.5493, 0.5000,\n",
      "        0.5403, 0.5384, 0.6141, 0.4988, 0.4995, 0.4993, 0.4995, 0.5325, 0.5792,\n",
      "        0.4992, 0.5640, 0.5985], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5297, 0.5672, 0.4996, 0.4994, 0.4996, 0.4992, 0.5392, 0.5000, 0.4997,\n",
      "        0.5000, 0.5051, 0.5859, 0.5970, 0.4991, 0.5308, 0.5358, 0.5491, 0.4999,\n",
      "        0.5391, 0.5372, 0.6122, 0.4989, 0.4995, 0.4993, 0.4995, 0.5319, 0.5784,\n",
      "        0.4992, 0.5627, 0.5975], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5304, 0.5691, 0.4996, 0.4994, 0.4996, 0.4992, 0.5404, 0.5000, 0.4997,\n",
      "        0.5000, 0.5051, 0.5884, 0.5997, 0.4991, 0.5318, 0.5369, 0.5503, 0.4999,\n",
      "        0.5401, 0.5382, 0.6151, 0.4988, 0.4995, 0.4993, 0.4995, 0.5326, 0.5804,\n",
      "        0.4992, 0.5645, 0.6001], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:51<16:24, 25.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5290, 0.5677, 0.4996, 0.4994, 0.4996, 0.4992, 0.5394, 0.5000, 0.4997,\n",
      "        0.5000, 0.5047, 0.5864, 0.5963, 0.4991, 0.5309, 0.5353, 0.5492, 0.4999,\n",
      "        0.5387, 0.5368, 0.6116, 0.4989, 0.4995, 0.4993, 0.4995, 0.5317, 0.5784,\n",
      "        0.4992, 0.5623, 0.5976], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5292, 0.5684, 0.4996, 0.4994, 0.4996, 0.4992, 0.5399, 0.5000, 0.4997,\n",
      "        0.5000, 0.5047, 0.5873, 0.5972, 0.4991, 0.5313, 0.5357, 0.5496, 0.4999,\n",
      "        0.5390, 0.5371, 0.6126, 0.4988, 0.4995, 0.4993, 0.4995, 0.5319, 0.5791,\n",
      "        0.4992, 0.5629, 0.5985], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 2/40 - Train Loss: 0.3462 - Val Loss: 0.0000\n",
      "\n",
      "tensor([0.5289, 0.5675, 0.4996, 0.4994, 0.4996, 0.4992, 0.5393, 0.5000, 0.4997,\n",
      "        0.5000, 0.5047, 0.5861, 0.5959, 0.4991, 0.5308, 0.5351, 0.5490, 0.4999,\n",
      "        0.5386, 0.5366, 0.6111, 0.4989, 0.4995, 0.4993, 0.4995, 0.5315, 0.5781,\n",
      "        0.4992, 0.5620, 0.5973], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5295, 0.5692, 0.4996, 0.4994, 0.4996, 0.4992, 0.5403, 0.5000, 0.4997,\n",
      "        0.5000, 0.5047, 0.5882, 0.5982, 0.4991, 0.5316, 0.5361, 0.5501, 0.4999,\n",
      "        0.5394, 0.5374, 0.6137, 0.4988, 0.4995, 0.4993, 0.4995, 0.5322, 0.5799,\n",
      "        0.4992, 0.5636, 0.5995], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5298, 0.5663, 0.4996, 0.4994, 0.4996, 0.4992, 0.5388, 0.5000, 0.4997,\n",
      "        0.5000, 0.5052, 0.5851, 0.5965, 0.4992, 0.5304, 0.5357, 0.5486, 0.5000,\n",
      "        0.5391, 0.5372, 0.6116, 0.4989, 0.4995, 0.4993, 0.4995, 0.5317, 0.5778,\n",
      "        0.4992, 0.5622, 0.5967], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5313, 0.5703, 0.4996, 0.4994, 0.4996, 0.4992, 0.5413, 0.5000, 0.4997,\n",
      "        0.5000, 0.5053, 0.5902, 0.6021, 0.4991, 0.5325, 0.5380, 0.5513, 0.4999,\n",
      "        0.5411, 0.5391, 0.6179, 0.4988, 0.4994, 0.4993, 0.4995, 0.5333, 0.5821,\n",
      "        0.4992, 0.5662, 0.6022], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5306, 0.5665, 0.4996, 0.4994, 0.4996, 0.4992, 0.5390, 0.5000, 0.4997,\n",
      "        0.5000, 0.5055, 0.5855, 0.5978, 0.4991, 0.5306, 0.5364, 0.5487, 0.5000,\n",
      "        0.5397, 0.5378, 0.6129, 0.4988, 0.4995, 0.4993, 0.4995, 0.5321, 0.5785,\n",
      "        0.4992, 0.5631, 0.5975], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5308, 0.5669, 0.4996, 0.4994, 0.4996, 0.4992, 0.5392, 0.5000, 0.4997,\n",
      "        0.5000, 0.5055, 0.5860, 0.5983, 0.4991, 0.5308, 0.5366, 0.5490, 0.5000,\n",
      "        0.5399, 0.5380, 0.6135, 0.4988, 0.4995, 0.4993, 0.4995, 0.5323, 0.5789,\n",
      "        0.4992, 0.5635, 0.5980], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5315, 0.5663, 0.4996, 0.4994, 0.4996, 0.4992, 0.5388, 0.5000, 0.4997,\n",
      "        0.5000, 0.5058, 0.5852, 0.5981, 0.4992, 0.5303, 0.5368, 0.5483, 0.5000,\n",
      "        0.5403, 0.5382, 0.6132, 0.4988, 0.4995, 0.4993, 0.4995, 0.5323, 0.5786,\n",
      "        0.4992, 0.5635, 0.5977], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5314, 0.5661, 0.4996, 0.4994, 0.4996, 0.4992, 0.5387, 0.5000, 0.4997,\n",
      "        0.5000, 0.5058, 0.5851, 0.5979, 0.4992, 0.5303, 0.5367, 0.5482, 0.5000,\n",
      "        0.5402, 0.5381, 0.6130, 0.4988, 0.4995, 0.4993, 0.4995, 0.5322, 0.5784,\n",
      "        0.4992, 0.5633, 0.5975], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5314, 0.5660, 0.4996, 0.4994, 0.4996, 0.4992, 0.5387, 0.5000, 0.4997,\n",
      "        0.5000, 0.5056, 0.5842, 0.5968, 0.4991, 0.5295, 0.5370, 0.5479, 0.5000,\n",
      "        0.5422, 0.5388, 0.6115, 0.4989, 0.4995, 0.4993, 0.4995, 0.5318, 0.5785,\n",
      "        0.4993, 0.5635, 0.5968], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5317, 0.5665, 0.4996, 0.4994, 0.4996, 0.4992, 0.5390, 0.5000, 0.4997,\n",
      "        0.5000, 0.5057, 0.5849, 0.5976, 0.4991, 0.5298, 0.5374, 0.5482, 0.5000,\n",
      "        0.5425, 0.5391, 0.6124, 0.4988, 0.4995, 0.4993, 0.4995, 0.5320, 0.5791,\n",
      "        0.4992, 0.5641, 0.5975], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [01:17<16:00, 25.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5320, 0.5682, 0.4996, 0.4994, 0.4996, 0.4992, 0.5405, 0.5000, 0.4997,\n",
      "        0.5000, 0.5055, 0.5881, 0.6003, 0.4991, 0.5310, 0.5381, 0.5494, 0.5000,\n",
      "        0.5427, 0.5395, 0.6157, 0.4988, 0.4994, 0.4993, 0.4995, 0.5329, 0.5810,\n",
      "        0.4992, 0.5656, 0.6004], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5311, 0.5658, 0.4996, 0.4994, 0.4996, 0.4992, 0.5390, 0.5000, 0.4997,\n",
      "        0.5000, 0.5054, 0.5849, 0.5968, 0.4991, 0.5298, 0.5367, 0.5478, 0.5000,\n",
      "        0.5414, 0.5383, 0.6119, 0.4988, 0.4995, 0.4993, 0.4995, 0.5319, 0.5785,\n",
      "        0.4993, 0.5632, 0.5972], grad_fn=<SigmoidBackward0>)\n",
      "Epoch 3/40 - Train Loss: 0.3462 - Val Loss: 0.0000\n",
      "\n",
      "tensor([0.5310, 0.5657, 0.4996, 0.4994, 0.4996, 0.4992, 0.5389, 0.5000, 0.4997,\n",
      "        0.5000, 0.5054, 0.5848, 0.5966, 0.4991, 0.5297, 0.5366, 0.5477, 0.5000,\n",
      "        0.5413, 0.5382, 0.6117, 0.4988, 0.4995, 0.4993, 0.4995, 0.5318, 0.5783,\n",
      "        0.4993, 0.5630, 0.5970], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.5311, 0.5659, 0.4996, 0.4994, 0.4996, 0.4992, 0.5391, 0.5000, 0.4997,\n",
      "        0.5000, 0.5054, 0.5851, 0.5970, 0.4991, 0.5299, 0.5367, 0.5479, 0.5000,\n",
      "        0.5414, 0.5383, 0.6121, 0.4988, 0.4995, 0.4993, 0.4995, 0.5319, 0.5786,\n",
      "        0.4993, 0.5633, 0.5973], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [01:18<16:05, 26.10s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m batch_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m     (graphs, lzs, base_bdis) \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/big/container/psilocybrain/utils.py:94\u001b[0m, in \u001b[0;36mBrainGraphDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     92\u001b[0m     lz_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cwd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlempel_ziv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_labels\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     93\u001b[0m     lz \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgenfromtxt(lz_path, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m     repr_end \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mtensor(graph)\u001b[38;5;241m.\u001b[39mfloat(), torch\u001b[38;5;241m.\u001b[39mtensor(lz)\u001b[38;5;241m.\u001b[39mfloat(), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetting \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_red\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mrepr\u001b[39m \u001b[38;5;241m=\u001b[39m graph_to_repr(graph, linear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear)\n",
      "File \u001b[0;32m~/big/container/psilocybrain/utils.py:82\u001b[0m, in \u001b[0;36mBrainGraphDataset.get_data_label\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 82\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatient_n\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatient_n\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(match\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_n\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pandas/core/indexing.py:1292\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m   1294\u001b[0m \n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pandas/core/indexing.py:1093\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1091\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(labels, key)\n\u001b[1;32m   1092\u001b[0m inds \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3896\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3900\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3902\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3903\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   3904\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pandas/core/generic.py:3892\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3884\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m   3886\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[1;32m   3887\u001b[0m     indices,\n\u001b[1;32m   3888\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[1;32m   3889\u001b[0m     verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   3890\u001b[0m     convert_indices\u001b[38;5;241m=\u001b[39mconvert_indices,\n\u001b[1;32m   3891\u001b[0m )\n\u001b[0;32m-> 3892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pandas/core/frame.py:630\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (BlockManager, ArrayManager)):\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# first check if a Manager is passed without any other arguments\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;66;03m# -> use fastpath (without checking Manager type)\u001b[39;00m\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m copy:\n\u001b[1;32m    629\u001b[0m         \u001b[38;5;66;03m# GH#33357 fastpath\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m         \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    633\u001b[0m manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pandas/core/generic.py:275\u001b[0m, in \u001b[0;36mNDFrame.__init__\u001b[0;34m(self, data, copy, attrs)\u001b[0m\n\u001b[1;32m    273\u001b[0m     attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(attrs)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_attrs\u001b[39m\u001b[38;5;124m\"\u001b[39m, attrs)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_flags\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mFlags\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallows_duplicate_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/pandas/core/flags.py:51\u001b[0m, in \u001b[0;36mFlags.__init__\u001b[0;34m(self, obj, allows_duplicate_labels)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m, allows_duplicate_labels) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allows_duplicate_labels \u001b[38;5;241m=\u001b[39m allows_duplicate_labels\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m \u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_epochs = 40\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "    \n",
    "    batch_counter = 0\n",
    "    loss = 0.\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        (graphs, lzs, base_bdis) = data\n",
    "        graphs = graphs.to(device)\n",
    "        lzs = lzs.to(device)      \n",
    "        u = base_bdis.to(device)\n",
    "        \n",
    "        if graphs.shape[0] == 1:\n",
    "            continue\n",
    "        \n",
    "        edge_attr_0 = graphs[:1, model.edge_index[0], model.edge_index[1]].t().view(-1)\n",
    "        edge_attr_0 = edge_attr_0 / torch.norm(edge_attr_0, p=2)\n",
    "        lz_0 = lzs[0].t().view(100, 1)\n",
    "        u_0 = u[0].view(1, 2)\n",
    "        hs_0, s_0 = model(lz_0, edge_attr_0, u_0)\n",
    "        \n",
    "        \n",
    "        edge_attr_1 = graphs[1:, model.edge_index[0], model.edge_index[1]].t().view(-1)\n",
    "        edge_attr_1 = edge_attr_1 / torch.norm(edge_attr_1, p=2)\n",
    "        lz_1 = lzs[1].t().view(100, 1)\n",
    "        u_1 = u[1].view(1, 2)\n",
    "        hs_1, s_1 = model(lz_1, edge_attr_1, u_1)\n",
    "\n",
    "\n",
    "        \n",
    "        loss = model.loss_function(hs_0, hs_1, s_0, s_1)\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(s_1)\n",
    "            print(s_0)\n",
    "        \n",
    "#         batch_counter += 1\n",
    "#         if batch_counter % batch_size == 0 or len(train_loader) == 0:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        loss = 0.\n",
    "    # validation\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (data, _) in enumerate(val_loader):\n",
    "#             (graph, lz, base_bdi) = data\n",
    "#             graph = graph.to(device)\n",
    "#             lz = lz.t().to(device)\n",
    "\n",
    "#             edge_attr = graph[:, model.edge_index[0], model.edge_index[1]].t().to(device)        \n",
    "#             u = base_bdi.to(device)\n",
    "\n",
    "#             recon_x, recon_edge_attr, recon_u, mu, logvar = model(lz, edge_attr, u)\n",
    "            \n",
    "#             loss = model.loss_function(recon_x.view(lz.shape), lz, recon_edge_attr.view(edge_attr.shape), edge_attr, recon_u.view(u.shape), u, mu, logvar)\n",
    "            \n",
    "#             val_loss += loss.item()\n",
    "    # append losses to lists\n",
    "    train_losses.append(train_loss/len(dataset))\n",
    "    val_losses.append(val_loss/len(psilo_dataset))\n",
    "\n",
    "    # save the model if the validation loss is at its minimum\n",
    "    if val_losses[-1] < best_val_loss:\n",
    "        best_val_loss = val_losses[-1]\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "    # print the lossestorch.nn.init.xavier_uniform_\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {train_losses[-1]:.4f} - Val Loss: {val_losses[-1]:.4f}\\n')\n",
    "    with open('gmm_train.txt', 'a') as f:\n",
    "        f.write(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {train_losses[-1]:.4f} - Val Loss: {val_losses[-1]:.4f}\\n')\n",
    "\n",
    "# save the best model for this configuration\n",
    "torch.save(best_model_state, f'vgae_weights/meta_layers_best_overfit.pt')\n",
    "\n",
    "# add the loss curves to the dictionary\n",
    "loss_curves[f\"loss_curves\"] = {\"train_loss\": train_losses, \"val_loss\": val_losses}\n",
    "\n",
    "# save the loss curves to a file\n",
    "with open(\"loss_curves_meta_layers.json\", \"w\") as f:\n",
    "    json.dump(loss_curves, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load in the loss curves from file\n",
    "with open(\"loss_curves_meta_layers.json\", \"r\") as f:\n",
    "    loss_curves = json.load(f)\n",
    "\n",
    "# plot the validation loss curves for each number of GMM components\n",
    "plt.figure(figsize=(8, 6))\n",
    "for n_comp, loss_dict in loss_curves.items():\n",
    "\n",
    "    val_losses = loss_dict[\"val_loss\"]\n",
    "    epochs = range(1, len(val_losses) + 1)\n",
    "    plt.plot(epochs, val_losses, label=f\"{n_comp}\")\n",
    "\n",
    "# add labels and legend\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.title(\"Validation Loss Curves for MetaLayers\")\n",
    "plt.legend()\n",
    "plt.ylim((1500, 3000))\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load in the loss curves from file\n",
    "with open(\"loss_curves_meta_layers.json\", \"r\") as f:\n",
    "    loss_curves = json.load(f)\n",
    "\n",
    "# plot the validation loss curves for each number of GMM components\n",
    "plt.figure(figsize=(8, 6))\n",
    "for n_comp, loss_dict in loss_curves.items():\n",
    "    val_losses = loss_dict[\"train_loss\"]\n",
    "    epochs = range(1, len(val_losses) + 1)\n",
    "    plt.plot(epochs, val_losses, label=f\"{n_comp}\")\n",
    "\n",
    "# add labels and legend\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Training Loss Curves for MetaLayers\")\n",
    "plt.legend()\n",
    "plt.ylim((0, 100))\n",
    "\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Layer: Validation Loss = 1.2679\n"
     ]
    }
   ],
   "source": [
    "# load the weights\n",
    "# model.load_state_dict(torch.load(f'vgae_weights/meta_layers_best_overfit.pt', map_location=device))\n",
    "\n",
    "# set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# calculate the validation loss\n",
    "val_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        (graph, lz, base_bdi) = data\n",
    "        graph = graph.to(device)\n",
    "        lz = lz.t().to(device)\n",
    "\n",
    "        edge_attr = graph[:, model.edge_index[0], model.edge_index[1]].t().to(device)        \n",
    "        u = base_bdi.to(device)\n",
    "\n",
    "        recon_x, recon_edge_attr, recon_u, mu, logvar = model(lz, edge_attr, u)\n",
    "        loss = model.loss_function(recon_x.view(lz.shape), lz, recon_edge_attr.view(edge_attr.shape), edge_attr, recon_u.view(u.shape), u, mu, logvar)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "\n",
    "# print the validation loss \n",
    "print(f'Meta Layer: Validation Loss = {val_loss/len(dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights\n",
    "model.load_state_dict(torch.load(f'vgae_weights/meta_layers_best_overfit.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (4950) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [4950, -1].  Tensor sizes: [2, 32]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m graph[:, model\u001b[38;5;241m.\u001b[39medge_index[\u001b[38;5;241m0\u001b[39m], model\u001b[38;5;241m.\u001b[39medge_index[\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39mt()\u001b[38;5;241m.\u001b[39mto(device)        \n\u001b[1;32m     13\u001b[0m u \u001b[38;5;241m=\u001b[39m base_bdi\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m recon_x, recon_edge_attr, u, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m recon_edge_attr \u001b[38;5;241m=\u001b[39m recon_edge_attr\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Create a SparseTensor object from the edge_index and edge_attr tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[93], line 43\u001b[0m, in \u001b[0;36mVGAE.forward\u001b[0;34m(self, x, edge_attr, u)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_attr, u):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[93], line 38\u001b[0m, in \u001b[0;36mVGAE.encode\u001b[0;34m(self, x, edge_attr, u)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_attr, u):\n\u001b[0;32m---> 38\u001b[0m     x, edge_attr, u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta_encode_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     hs, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_encode_2(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_index, edge_attr\u001b[38;5;241m=\u001b[39medge_attr, u\u001b[38;5;241m=\u001b[39mu)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreadout(hs)\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[82], line 42\u001b[0m, in \u001b[0;36mMetaLayer.forward\u001b[0;34m(self, x, edge_index, edge_attr, u, batch)\u001b[0m\n\u001b[1;32m     39\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_model(x, edge_index, edge_attr, u, batch)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_model(x, edge_index, edge_attr, u, batch)\n",
      "File \u001b[0;32m~/anaconda3/envs/fyp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[81], line 45\u001b[0m, in \u001b[0;36mEdgeModel.forward\u001b[0;34m(self, src, dest, edge_index, edge_attr, u, batch)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, dest, edge_index, edge_attr, u, batch):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# src, dest: [E, F_x], where E is the number of edges.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# edge_attr: [E, F_e]\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# u: [B, F_u], where B is the number of graphs.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# batch: [E] with max entry B - 1.\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([src, dest, edge_index\u001b[38;5;241m.\u001b[39mt(), edge_attr, \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m], \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_mlp(out)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (4950) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [4950, -1].  Tensor sizes: [2, 32]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "\n",
    "# select a batch from the validation data loader\n",
    "data, _ = next(iter(train_loader))\n",
    "\n",
    "# pass the batch through the trained model to obtain the reconstructed output\n",
    "(graph, lz, base_bdi) = data\n",
    "graph = graph.to(device)\n",
    "lz = lz.t().to(device)\n",
    "\n",
    "edge_attr = graph[:, model.edge_index[0], model.edge_index[1]].t().to(device)        \n",
    "u = base_bdi.to(device)\n",
    "\n",
    "recon_x, recon_edge_attr, u, _, _ = model(lz, edge_attr, u)\n",
    "\n",
    "recon_edge_attr = recon_edge_attr.detach()\n",
    "\n",
    "# Create a SparseTensor object from the edge_index and edge_attr tensors\n",
    "recon = torch.zeros((100, 100))\n",
    "\n",
    "for i in range(model.edge_index.shape[1]):\n",
    "    recon[model.edge_index[0,i], model.edge_index[1,i]] = recon_edge_attr[i]\n",
    "    recon[model.edge_index[1,i], model.edge_index[0,i]] = recon_edge_attr[i]\n",
    "\n",
    "# reshape the output to a 100x100 matrix (assuming the input_dim is 100x100)\n",
    "\n",
    "# plot the original and reconstructed matrices for the first sample in the batch\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "plotting.plot_matrix(graph.view(100, 100), colorbar=True, vmax=0.8, vmin=-0.8, axes=ax1)\n",
    "ax1.set_title('Original')\n",
    "plotting.plot_matrix(recon.detach(), colorbar=True, vmax=0.8, vmin=-0.8, axes=ax2)\n",
    "ax2.set_title('Reconstructed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = 'fc_matrices/psilo_ica_100_before'\n",
    "cwd = os.getcwd() + '/'\n",
    "\n",
    "psilo_dataset = BrainGraphDataset(img_dir=cwd + dataroot,\n",
    "                            annotations_file=cwd + annotations,\n",
    "                            transform=None, extra_data=None, setting='no_label')\n",
    "\n",
    "psilo_train_loader = DataLoader(psilo_dataset, batch_size=batch_size)\n",
    "\n",
    "# select a batch from the validation data loader\n",
    "data, _ = next(iter(psilo_train_loader))\n",
    "\n",
    "# pass the batch through the trained model to obtain the reconstructed output\n",
    "recon, _, _ = model(data.view(-1, input_dim))\n",
    "\n",
    "# reshape the output to a 100x100 matrix (assuming the input_dim is 100x100)\n",
    "recon = recon.view(-1, 100, 100)\n",
    "\n",
    "for i in range(3):\n",
    "    # plot the original and reconstructed matrices for the first sample in the batch\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    plotting.plot_matrix(data[i], colorbar=True, vmax=0.8, vmin=-0.8, axes=ax1)\n",
    "    ax1.set_title('Original')\n",
    "    plotting.plot_matrix(recon[i].detach(), colorbar=True, vmax=0.8, vmin=-0.8, axes=ax2)\n",
    "    ax2.set_title('Reconstructed')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGAE(input_dim, hidden_dim, latent_dim)\n",
    "\n",
    "# load the weights\n",
    "model.load_state_dict(torch.load(f'vgae_weights/gmm7_best.pt', map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "\n",
    "# set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# calculate the validation loss\n",
    "val_losses = []\n",
    "with torch.no_grad():\n",
    "    for n_comp in range(2, 11):\n",
    "        val_loss = 0.0\n",
    "        model.load_state_dict(torch.load(f'vgae_weights/gmm{n_comp}_best.pt', map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "        for batch_idx, (data, _) in enumerate(psilo_train_loader):\n",
    "            recon, mu, logvar = model(data.view(-1, input_dim))\n",
    "            loss = loss_function_gmm(recon, data.view(-1, input_dim), mu, logvar, n_components=5)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(psilo_dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'gmm_{n_comp}: {val_loss} loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_list = list(range(2, 11))\n",
    "\n",
    "# plot the validation loss for each n_components value\n",
    "plt.plot(n_components_list, val_losses)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss vs. Number of GMM Components')\n",
    "plt.savefig('gmm_component_testing.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 256\n",
    "latent_dim = 64\n",
    "input_dim = 100 * 100\n",
    "\n",
    "model = VGAE(input_dim, hidden_dim, latent_dim)\n",
    "\n",
    "model.load_state_dict(torch.load('vgae_weights/gmm_5_hidden256_latent64.pt'))\n",
    "\n",
    "psilo_mus = []\n",
    "hcp_mus = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, _) in enumerate(psilo_train_loader):\n",
    "        mu, _= model.encode(data.view(-1, input_dim))\n",
    "        psilo_mus.append(mu)\n",
    "    \n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        mu, _ = model.encode(data.view(-1, input_dim))\n",
    "        hcp_mus.append(mu)\n",
    "        \n",
    "psilo_mus = torch.stack(psilo_mus, dim=1)\n",
    "hcp_mus = torch.stack(hcp_mus, dim=1)\n",
    "        \n",
    "# Concatenate the encoded representations and create labels\n",
    "x = torch.cat((psilo_mus, hcp_mus), dim=0)\n",
    "labels = torch.cat((torch.zeros(psilo_mus.shape[0]), torch.ones(hcp_mus.shape[0])), dim=0)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "print(labels.shape)\n",
    "\n",
    "# Use t-SNE to reduce the dimensionality of the encoded representations\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)\n",
    "x_tsne = tsne.fit_transform(x)\n",
    "\n",
    "# Plot the t-SNE embeddings\n",
    "plt.scatter(x_tsne[:, 0], x_tsne[:, 1], c=labels, cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameters\n",
    "input_dim = 100 * 100  # size of the graph adjacency matrix\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "num_epochs = 300\n",
    "\n",
    "annotations = 'annotations.csv'\n",
    "\n",
    "dataroot = 'fc_matrices/hcp_100_ica/'\n",
    "cwd = os.getcwd() + '/'\n",
    "\n",
    "dataset = BrainGraphDataset(img_dir=cwd + dataroot,\n",
    "                            annotations_file=cwd + dataroot + annotations,\n",
    "                            transform=None, extra_data=None, setting='no_label')\n",
    "\n",
    "# define the data loaders\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# instantiate the model\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "loss_curves = {}\n",
    "best_val_losses = {}  # create a dictionary to store the best validation loss for each configuration\n",
    "\n",
    "best_n = 3\n",
    "\n",
    "for hidden_dim in [256, 512]:\n",
    "    for latent_dim in [64, 128]:\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        model = VGAE(input_dim, hidden_dim, latent_dim).to(device)  # move model to device\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        best_val_loss = float('inf')  # initialize the best validation loss to infinity\n",
    "        \n",
    "        with open('gmm_train_overfit.txt', 'a') as f:\n",
    "            f.write(f'Hidden dim: {hidden_dim}, latent_dim: {latent_dim}\\n')\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = 0.0\n",
    "            val_loss = 0.0\n",
    "\n",
    "            # training\n",
    "            model.train()\n",
    "            # define the optimizer and the loss function\n",
    "\n",
    "            for batch_idx, (data, _) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "                data = data.to(device)  # move input data to device\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                recon, mu, logvar = model(data.view(-1, input_dim))\n",
    "                loss = loss_function_gmm(recon, data.view(-1, input_dim), mu, logvar, n_components=best_n)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, _) in tqdm(enumerate(psilo_train_loader), total=len(psilo_train_loader)):\n",
    "                    data = data.to(device)  # move input data to device\n",
    "                    recon, mu, logvar = model(data.view(-1, input_dim))\n",
    "                    loss = loss_function_gmm(recon, data.view(-1, input_dim), mu, logvar, n_components=best_n)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            # append losses to lists\n",
    "            train_losses.append(train_loss/len(train_dataset))\n",
    "            val_losses.append(val_loss/len(psilo_dataset))\n",
    "\n",
    "            with open('gmm_train_overfit.txt', 'a') as f:\n",
    "                f.write(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {train_losses[-1]:.4f} - Val Loss: {val_losses[-1]:.4f}\\n')\n",
    "                \n",
    "            # update the best validation loss and save the model weights if it's the best so far for this configuration\n",
    "            if val_losses[-1] < best_val_loss:\n",
    "                best_val_loss = val_losses[-1]\n",
    "                best_val_losses[(hidden_dim, latent_dim)] = best_val_loss\n",
    "                torch.save(model.state_dict(), f'vgae_weights/gmm_{best_n}_hidden{hidden_dim}_latent{latent_dim}.pt')\n",
    "\n",
    "        # plot the losses\n",
    "        plt.plot(val_losses, label=f'Validation Loss (hidden_dim={hidden_dim}, latent_dim={latent_dim})')\n",
    "        \n",
    "                # add the loss curves to the dictionary\n",
    "        loss_curves[f\"hidden{hidden_dim}_latent_dim{latent_dim}\"] = {\"train_loss\": train_losses, \"val_loss\": val_losses}\n",
    "\n",
    "# save the loss curves to a file\n",
    "with open(\"loss_curves_overfit_new.json\", \"w\") as f:\n",
    "    json.dump(loss_curves, f)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load in the loss curves from file\n",
    "with open(\"loss_curves_overfit.json\", \"r\") as f:\n",
    "    loss_curves = json.load(f)\n",
    "\n",
    "# plot the validation loss curves for each number of GMM components\n",
    "plt.figure(figsize=(10, 8))\n",
    "for n_comp, loss_dict in loss_curves.items():\n",
    "    val_losses = loss_dict[\"val_loss\"]\n",
    "    epochs = range(1, len(val_losses) + 1)\n",
    "    plt.plot(epochs, val_losses, label=f\"{n_comp}\")\n",
    "\n",
    "# add labels and legend\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Val Loss\")\n",
    "plt.title(\"Validation Loss Curves for Different Net Architectures\")\n",
    "plt.legend()\n",
    "plt.ylim((350, 500))\n",
    "\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameters\n",
    "input_dim = 100 * 100  # size of the graph adjacency matrix\n",
    "hidden_dims = [256, 128, 64]\n",
    "latent_dims = [64, 32, 16]\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "num_epochs = 300\n",
    "\n",
    "annotations = 'annotations.csv'\n",
    "\n",
    "dataroot = 'fc_matrices/hcp_100_ica/'\n",
    "cwd = os.getcwd() + '/'\n",
    "\n",
    "\n",
    "# define the optimizer and the loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for hidden_dim in hidden_dims:\n",
    "    for latent_dim in latent_dims:\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        model = VGAE(input_dim, hidden_dim, latent_dim)\n",
    "        \n",
    "        # load in the model weights\n",
    "        model.load_state_dict(torch.load(f'vgae_weights/gmm_5_hidden{hidden_dim}_latent{latent_dim}.pt'))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            for batch_idx, (data, _) in tqdm(enumerate(psilo_train_loader), total=len(psilo_train_loader)):\n",
    "                recon, mu, logvar = model(data.view(-1, input_dim))\n",
    "                loss = loss_function_gmm(recon, data.view(-1, input_dim), mu, logvar, n_components=5)\n",
    "                val_loss += loss.item()\n",
    "            val_losses.append(val_loss/len(psilo_dataset))\n",
    "\n",
    "        # print the validation loss for this configuration\n",
    "        print(f'Hidden Dim: {hidden_dim}, Latent Dim: {latent_dim}, Validation Loss: {val_losses[-1]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentMLP(nn.Module):\n",
    "    def __init__(self, latent_dim: int, hidden_dim: int, output_dim: int):\n",
    "        super(LatentMLP, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the VGAE model\n",
    "hidden_dim = 256\n",
    "latent_dim = 64\n",
    "input_dim = 100 * 100\n",
    "output_dim = 1\n",
    "\n",
    "vgae = VGAE(input_dim, hidden_dim, latent_dim)\n",
    "\n",
    "# load the trained VGAE weights\n",
    "vgae.load_state_dict(torch.load('vgae_weights/gmm_5_hidden256_latent64.pt'))\n",
    "\n",
    "# freeze the weights of the VGAE\n",
    "for param in vgae.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# instantiate the LatentMLP model\n",
    "mlp = LatentMLP(latent_dim, hidden_dim, output_dim)\n",
    "\n",
    "# define the optimizer and the loss function\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "dataroot = 'fc_matrices/psilo_100_ica/'\n",
    "cwd = os.getcwd() + '/'\n",
    "\n",
    "dataset = BrainGraphDataset(img_dir=cwd + dataroot,\n",
    "                            annotations_file=annotations,\n",
    "                            transform=None, extra_data=None, setting='no_label')\n",
    "\n",
    "# # define the data loader for the new dataset\n",
    "# new_dataset = MyNewDataset()\n",
    "# new_loader = DataLoader(new_dataset, batch_size=batch_size)\n",
    "\n",
    "# train the MLP on the new dataset\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(psilo_train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get the latent embeddings from the VGAE\n",
    "        _, mu, _ = vgae(inputs)\n",
    "        \n",
    "        # pass the latent embeddings through the MLP\n",
    "        outputs = mlp(mu)\n",
    "        \n",
    "        # calculate the loss and backpropagate\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "bfcbe3febb699c87ff4898d01faf13d6a57f0e8fbe0b31d844ec717796aaa0a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
