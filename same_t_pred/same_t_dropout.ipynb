{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import BrainGraphDataset, project_root\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils.data import ConcatDataset\n",
    "from models import VAE, SameTPred\n",
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lr = 0.001\n",
    "batch_size = 32\n",
    "input_dim = 4950\n",
    "\n",
    "# define the optimizer and the loss function\n",
    "\n",
    "criterion = nn.L1Loss(reduction='sum')\n",
    "\n",
    "root = project_root()\n",
    "\n",
    "dataroot = 'fc_matrices/psilo_schaefer_before'\n",
    "annotations = 'annotations-before.csv'\n",
    "before_dataset = BrainGraphDataset(img_dir=os.path.join(root, dataroot),\n",
    "                            annotations_file=os.path.join(root, annotations),\n",
    "                            transform=None, extra_data=None, setting='upper_triangular')\n",
    "\n",
    "dataroot = 'fc_matrices/psilo_schaefer_after'\n",
    "annotations = 'annotations-after.csv'\n",
    "after_dataset = BrainGraphDataset(img_dir=os.path.join(root, dataroot),\n",
    "                            annotations_file=os.path.join(root, annotations),\n",
    "                            transform=None, extra_data=None, setting='upper_triangular')\n",
    "\n",
    "dataset = ConcatDataset([before_dataset, after_dataset])\n",
    "\n",
    "# Define the train, validation, and test ratios\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Get the number of samples in the dataset\n",
    "num_samples = len(dataset)\n",
    "\n",
    "# Calculate the number of samples for each set\n",
    "train_size = int(train_ratio * num_samples)\n",
    "val_size = int(val_ratio * num_samples)\n",
    "test_size = num_samples - train_size - val_size\n",
    "\n",
    "torch.manual_seed(0)\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(val_set, batch_size=test_size, shuffle=False)\n",
    "\n",
    "results = []\n",
    "values = {}\n",
    "dropout_list = [0, 0.05 ,0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "\n",
    "for dropout in dropout_list:\n",
    "\n",
    "    vae = VAE(4950, [128] * 2, 64)\n",
    "    vae.load_state_dict(torch.load(os.path.join(root, 'same_t_pred', f'vae_unfrozen_dropout_{dropout}.pt'), \n",
    "                                   map_location=device))\n",
    "    vae = vae.to(device)\n",
    "\n",
    "    model = SameTPred(64, 256, dropout=dropout)\n",
    "    model.load_state_dict(torch.load(os.path.join(root, 'same_t_pred', f'same_t_weight_dropout_{dropout}.pt'), \n",
    "                          map_location=device))\n",
    "\n",
    "    # Convert the MLP to the device\n",
    "    model.to(device)\n",
    "\n",
    "    # Validation check\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            graphs, labels = data\n",
    "\n",
    "            graphs = graphs.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            _, _, _, z = vae(graphs.view(-1, input_dim))\n",
    "\n",
    "            preds = model(z)\n",
    "\n",
    "            labels = labels.view(-1).cpu().numpy()\n",
    "            preds = preds.view(-1).cpu().numpy()\n",
    "            \n",
    "            mae = mean_absolute_error(labels, preds)\n",
    "            corr_coeffs = pearsonr(labels, preds)\n",
    "            r2 = r2_score(labels, preds)\n",
    "\n",
    "            results.append((dropout, mae, corr_coeffs[0], corr_coeffs[1], r2))\n",
    "            values[f'{dropout}'] = {'ground': labels.tolist(), 'predicted': preds.tolist()}\n",
    "            \n",
    "import csv\n",
    "import json\n",
    "\n",
    "with open(os.path.join(root, 'same_t_pred', 'test_results.json'), 'w') as f:\n",
    "    json.dump(values, f)\n",
    "\n",
    "csv_filename = os.path.join(root, 'same_t_pred', 'same_t_dropout_results.csv')\n",
    "# Write the results to the CSV file\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write the header row\n",
    "    writer.writerow([\"Dropout\", \"MAE\", \"Pearson stat\", \"Pearson p-value\", \"R2 Score\"])\n",
    "    \n",
    "    # Write the data rows\n",
    "    for result in results:\n",
    "        writer.writerow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
