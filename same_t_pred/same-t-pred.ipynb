{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 18.529, val_loss: 20.444\n",
      "[2] loss: 16.833, val_loss: 16.898\n",
      "[3] loss: 14.037, val_loss: 10.810\n",
      "[4] loss: 10.681, val_loss: 10.046\n",
      "[5] loss: 10.795, val_loss: 10.751\n",
      "[6] loss: 10.451, val_loss: 8.672\n",
      "[7] loss: 9.720, val_loss: 8.201\n",
      "[8] loss: 10.102, val_loss: 8.174\n",
      "[9] loss: 10.062, val_loss: 8.384\n",
      "[10] loss: 9.707, val_loss: 9.108\n",
      "[11] loss: 9.718, val_loss: 9.573\n",
      "[12] loss: 9.509, val_loss: 8.746\n",
      "[13] loss: 9.544, val_loss: 8.293\n",
      "[14] loss: 9.580, val_loss: 8.500\n",
      "[15] loss: 9.674, val_loss: 9.440\n",
      "[16] loss: 9.337, val_loss: 8.690\n",
      "[17] loss: 9.233, val_loss: 8.437\n",
      "[18] loss: 9.292, val_loss: 8.507\n",
      "[19] loss: 9.132, val_loss: 9.011\n",
      "[20] loss: 9.113, val_loss: 8.730\n",
      "[21] loss: 8.984, val_loss: 8.535\n",
      "[22] loss: 8.985, val_loss: 8.449\n",
      "[23] loss: 8.928, val_loss: 8.690\n",
      "[24] loss: 8.815, val_loss: 8.557\n",
      "[25] loss: 8.803, val_loss: 8.556\n",
      "[26] loss: 8.796, val_loss: 8.526\n",
      "[27] loss: 8.755, val_loss: 8.532\n",
      "[28] loss: 8.592, val_loss: 7.950\n",
      "[29] loss: 8.742, val_loss: 8.196\n",
      "[30] loss: 8.560, val_loss: 8.343\n",
      "[31] loss: 8.579, val_loss: 8.105\n",
      "[32] loss: 8.515, val_loss: 8.239\n",
      "[33] loss: 8.415, val_loss: 8.055\n",
      "[34] loss: 8.387, val_loss: 8.174\n",
      "[35] loss: 8.311, val_loss: 8.133\n",
      "[36] loss: 8.306, val_loss: 7.883\n",
      "[37] loss: 8.325, val_loss: 8.527\n",
      "[38] loss: 8.266, val_loss: 7.931\n",
      "[39] loss: 8.190, val_loss: 8.114\n",
      "[40] loss: 8.107, val_loss: 8.069\n",
      "[41] loss: 8.196, val_loss: 7.919\n",
      "[42] loss: 8.080, val_loss: 7.972\n",
      "[43] loss: 8.016, val_loss: 7.848\n",
      "[44] loss: 8.023, val_loss: 7.839\n",
      "[45] loss: 7.907, val_loss: 8.277\n",
      "[46] loss: 7.882, val_loss: 8.253\n",
      "[47] loss: 8.394, val_loss: 7.851\n",
      "[48] loss: 7.728, val_loss: 8.231\n",
      "[49] loss: 7.998, val_loss: 7.895\n",
      "[50] loss: 7.973, val_loss: 7.674\n",
      "[51] loss: 7.734, val_loss: 8.232\n",
      "[52] loss: 7.869, val_loss: 8.070\n",
      "[53] loss: 7.914, val_loss: 7.752\n",
      "[54] loss: 7.669, val_loss: 7.658\n",
      "[55] loss: 7.453, val_loss: 7.694\n",
      "[56] loss: 7.510, val_loss: 7.568\n",
      "[57] loss: 7.350, val_loss: 7.817\n",
      "[58] loss: 7.450, val_loss: 7.928\n",
      "[59] loss: 7.299, val_loss: 7.890\n",
      "[60] loss: 7.186, val_loss: 7.934\n",
      "[61] loss: 7.386, val_loss: 9.196\n",
      "[62] loss: 8.416, val_loss: 9.218\n",
      "[63] loss: 8.087, val_loss: 7.923\n",
      "[64] loss: 7.776, val_loss: 7.656\n",
      "[65] loss: 7.334, val_loss: 8.749\n",
      "[66] loss: 7.648, val_loss: 7.853\n",
      "[67] loss: 7.430, val_loss: 7.807\n",
      "[68] loss: 7.365, val_loss: 8.507\n",
      "[69] loss: 7.410, val_loss: 7.861\n",
      "[70] loss: 7.208, val_loss: 7.895\n",
      "[71] loss: 7.043, val_loss: 8.027\n",
      "[72] loss: 6.988, val_loss: 7.911\n",
      "[73] loss: 6.919, val_loss: 7.904\n",
      "[74] loss: 6.919, val_loss: 8.515\n",
      "[75] loss: 7.101, val_loss: 8.263\n",
      "[76] loss: 6.754, val_loss: 8.190\n",
      "[77] loss: 7.093, val_loss: 9.157\n",
      "[78] loss: 7.700, val_loss: 9.066\n",
      "[79] loss: 7.011, val_loss: 8.681\n",
      "[80] loss: 7.723, val_loss: 8.780\n",
      "[81] loss: 7.266, val_loss: 9.251\n",
      "[82] loss: 7.080, val_loss: 8.206\n",
      "[83] loss: 7.054, val_loss: 8.605\n",
      "[84] loss: 7.090, val_loss: 9.108\n",
      "[85] loss: 6.790, val_loss: 8.161\n",
      "[86] loss: 6.936, val_loss: 8.489\n",
      "[87] loss: 6.755, val_loss: 9.050\n",
      "[88] loss: 6.761, val_loss: 8.393\n",
      "[89] loss: 6.651, val_loss: 8.955\n",
      "[90] loss: 6.733, val_loss: 8.873\n",
      "[91] loss: 6.277, val_loss: 8.486\n",
      "[92] loss: 6.755, val_loss: 9.360\n",
      "[93] loss: 7.018, val_loss: 9.522\n",
      "[94] loss: 6.641, val_loss: 8.629\n",
      "[95] loss: 6.881, val_loss: 9.079\n",
      "[96] loss: 6.408, val_loss: 8.851\n",
      "[97] loss: 5.978, val_loss: 8.703\n",
      "[98] loss: 6.201, val_loss: 9.539\n",
      "[99] loss: 6.421, val_loss: 9.295\n",
      "[100] loss: 6.056, val_loss: 8.940\n",
      "[101] loss: 6.154, val_loss: 9.750\n",
      "[102] loss: 6.545, val_loss: 8.882\n",
      "[103] loss: 5.822, val_loss: 8.702\n",
      "[104] loss: 5.776, val_loss: 9.493\n",
      "[105] loss: 6.118, val_loss: 9.164\n",
      "[106] loss: 6.681, val_loss: 9.963\n",
      "[107] loss: 6.766, val_loss: 9.602\n",
      "[108] loss: 5.947, val_loss: 9.269\n",
      "[109] loss: 6.006, val_loss: 10.322\n",
      "[110] loss: 6.809, val_loss: 9.837\n",
      "[111] loss: 6.141, val_loss: 9.222\n",
      "[112] loss: 6.588, val_loss: 9.614\n",
      "[113] loss: 6.230, val_loss: 9.808\n",
      "[114] loss: 5.992, val_loss: 9.349\n",
      "[115] loss: 6.492, val_loss: 9.603\n",
      "[116] loss: 5.557, val_loss: 9.713\n",
      "[117] loss: 5.395, val_loss: 9.455\n",
      "[118] loss: 6.369, val_loss: 9.757\n",
      "[119] loss: 6.050, val_loss: 9.378\n",
      "[120] loss: 5.407, val_loss: 9.479\n",
      "[121] loss: 5.512, val_loss: 9.850\n",
      "[122] loss: 5.276, val_loss: 9.726\n",
      "[123] loss: 5.274, val_loss: 10.208\n",
      "[124] loss: 6.407, val_loss: 9.069\n",
      "[125] loss: 6.020, val_loss: 9.009\n",
      "[126] loss: 5.613, val_loss: 9.397\n",
      "[127] loss: 5.510, val_loss: 9.624\n",
      "[128] loss: 5.640, val_loss: 9.674\n",
      "[129] loss: 5.231, val_loss: 9.422\n",
      "[130] loss: 5.106, val_loss: 9.111\n",
      "[131] loss: 5.860, val_loss: 9.897\n",
      "[132] loss: 5.566, val_loss: 9.441\n",
      "[133] loss: 4.951, val_loss: 9.363\n",
      "[134] loss: 5.499, val_loss: 10.003\n",
      "[135] loss: 6.427, val_loss: 9.287\n",
      "[136] loss: 5.211, val_loss: 9.187\n",
      "[137] loss: 5.319, val_loss: 9.594\n",
      "[138] loss: 6.032, val_loss: 9.305\n",
      "[139] loss: 5.060, val_loss: 9.561\n",
      "[140] loss: 6.180, val_loss: 10.045\n",
      "[141] loss: 6.309, val_loss: 9.349\n",
      "[142] loss: 5.269, val_loss: 9.214\n",
      "[143] loss: 5.450, val_loss: 9.437\n",
      "[144] loss: 5.184, val_loss: 9.343\n",
      "[145] loss: 4.711, val_loss: 9.372\n",
      "[146] loss: 5.196, val_loss: 10.200\n",
      "[147] loss: 5.945, val_loss: 9.612\n",
      "[148] loss: 4.796, val_loss: 9.457\n",
      "[149] loss: 5.089, val_loss: 9.814\n",
      "[150] loss: 5.686, val_loss: 9.214\n",
      "[151] loss: 4.896, val_loss: 9.157\n",
      "[152] loss: 5.146, val_loss: 9.553\n",
      "[153] loss: 5.784, val_loss: 9.230\n",
      "[154] loss: 4.805, val_loss: 9.185\n",
      "[155] loss: 4.737, val_loss: 9.605\n",
      "[156] loss: 4.679, val_loss: 9.661\n",
      "[157] loss: 4.562, val_loss: 10.059\n",
      "[158] loss: 4.638, val_loss: 9.415\n",
      "[159] loss: 4.571, val_loss: 9.878\n",
      "[160] loss: 5.255, val_loss: 9.072\n",
      "[161] loss: 5.225, val_loss: 9.387\n",
      "[162] loss: 4.501, val_loss: 10.165\n",
      "[163] loss: 6.451, val_loss: 9.248\n",
      "[164] loss: 4.529, val_loss: 9.124\n",
      "[165] loss: 4.775, val_loss: 9.273\n",
      "[166] loss: 5.200, val_loss: 9.543\n",
      "[167] loss: 5.429, val_loss: 9.599\n",
      "[168] loss: 4.629, val_loss: 9.700\n",
      "[169] loss: 5.133, val_loss: 9.555\n",
      "[170] loss: 5.345, val_loss: 9.133\n",
      "[171] loss: 5.308, val_loss: 9.389\n",
      "[172] loss: 4.619, val_loss: 9.274\n",
      "[173] loss: 4.331, val_loss: 9.983\n",
      "[174] loss: 4.913, val_loss: 9.443\n",
      "[175] loss: 5.230, val_loss: 9.456\n",
      "[176] loss: 4.907, val_loss: 9.396\n",
      "[177] loss: 4.729, val_loss: 9.490\n",
      "[178] loss: 5.029, val_loss: 9.891\n",
      "[179] loss: 5.756, val_loss: 9.100\n",
      "[180] loss: 4.538, val_loss: 9.677\n",
      "[181] loss: 5.435, val_loss: 9.729\n",
      "[182] loss: 5.654, val_loss: 9.465\n",
      "[183] loss: 4.562, val_loss: 9.709\n",
      "[184] loss: 5.227, val_loss: 9.442\n",
      "[185] loss: 5.166, val_loss: 8.898\n",
      "[186] loss: 4.069, val_loss: 9.411\n",
      "[187] loss: 5.065, val_loss: 9.692\n",
      "[188] loss: 5.338, val_loss: 8.994\n",
      "[189] loss: 3.940, val_loss: 8.799\n",
      "[190] loss: 4.235, val_loss: 8.787\n",
      "[191] loss: 3.860, val_loss: 9.296\n",
      "[192] loss: 3.886, val_loss: 9.424\n",
      "[193] loss: 3.940, val_loss: 9.357\n",
      "[194] loss: 3.952, val_loss: 9.539\n",
      "[195] loss: 4.388, val_loss: 9.872\n",
      "[196] loss: 4.722, val_loss: 9.662\n",
      "[197] loss: 4.262, val_loss: 9.560\n",
      "[198] loss: 4.100, val_loss: 9.407\n",
      "[199] loss: 3.721, val_loss: 9.423\n",
      "[200] loss: 4.210, val_loss: 9.286\n",
      "[1] loss: 18.501, val_loss: 20.472\n",
      "[2] loss: 16.755, val_loss: 17.789\n",
      "[3] loss: 14.103, val_loss: 13.583\n",
      "[4] loss: 10.155, val_loss: 10.549\n",
      "[5] loss: 9.482, val_loss: 10.604\n",
      "[6] loss: 10.835, val_loss: 10.425\n",
      "[7] loss: 9.329, val_loss: 11.725\n",
      "[8] loss: 9.238, val_loss: 12.336\n",
      "[9] loss: 9.592, val_loss: 12.300\n",
      "[10] loss: 9.398, val_loss: 11.757\n",
      "[11] loss: 8.989, val_loss: 11.203\n",
      "[12] loss: 9.007, val_loss: 10.941\n",
      "[13] loss: 8.987, val_loss: 10.846\n",
      "[14] loss: 9.080, val_loss: 11.176\n",
      "[15] loss: 8.832, val_loss: 11.381\n",
      "[16] loss: 8.756, val_loss: 11.372\n",
      "[17] loss: 8.703, val_loss: 11.634\n",
      "[18] loss: 8.604, val_loss: 11.524\n",
      "[19] loss: 8.549, val_loss: 11.400\n",
      "[20] loss: 8.477, val_loss: 11.429\n",
      "[21] loss: 8.373, val_loss: 11.659\n",
      "[22] loss: 8.311, val_loss: 11.872\n",
      "[23] loss: 8.317, val_loss: 11.865\n",
      "[24] loss: 8.229, val_loss: 11.712\n",
      "[25] loss: 8.152, val_loss: 11.612\n",
      "[26] loss: 8.089, val_loss: 11.898\n",
      "[27] loss: 8.048, val_loss: 11.950\n",
      "[28] loss: 8.119, val_loss: 11.697\n",
      "[29] loss: 7.913, val_loss: 11.479\n",
      "[30] loss: 7.830, val_loss: 11.475\n",
      "[31] loss: 7.792, val_loss: 11.640\n",
      "[32] loss: 7.655, val_loss: 11.696\n",
      "[33] loss: 7.707, val_loss: 11.565\n",
      "[34] loss: 7.477, val_loss: 11.684\n",
      "[35] loss: 7.322, val_loss: 11.416\n",
      "[36] loss: 7.312, val_loss: 11.799\n",
      "[37] loss: 7.289, val_loss: 11.262\n",
      "[38] loss: 7.033, val_loss: 11.429\n",
      "[39] loss: 6.946, val_loss: 11.578\n",
      "[40] loss: 6.821, val_loss: 11.688\n",
      "[41] loss: 7.116, val_loss: 11.928\n",
      "[42] loss: 7.177, val_loss: 12.291\n",
      "[43] loss: 7.022, val_loss: 12.233\n",
      "[44] loss: 6.991, val_loss: 12.350\n",
      "[45] loss: 6.582, val_loss: 12.311\n",
      "[46] loss: 6.493, val_loss: 12.256\n",
      "[47] loss: 6.389, val_loss: 12.380\n",
      "[48] loss: 6.544, val_loss: 12.670\n",
      "[49] loss: 6.236, val_loss: 12.646\n",
      "[50] loss: 6.280, val_loss: 12.614\n",
      "[51] loss: 6.867, val_loss: 12.776\n",
      "[52] loss: 5.972, val_loss: 12.801\n",
      "[53] loss: 6.310, val_loss: 12.751\n",
      "[54] loss: 6.283, val_loss: 12.877\n",
      "[55] loss: 5.966, val_loss: 13.089\n",
      "[56] loss: 5.846, val_loss: 13.330\n",
      "[57] loss: 5.903, val_loss: 13.281\n",
      "[58] loss: 5.592, val_loss: 12.920\n",
      "[59] loss: 6.119, val_loss: 13.153\n",
      "[60] loss: 5.427, val_loss: 13.257\n",
      "[61] loss: 5.934, val_loss: 13.513\n",
      "[62] loss: 6.266, val_loss: 13.138\n",
      "[63] loss: 5.739, val_loss: 13.246\n",
      "[64] loss: 5.827, val_loss: 13.357\n",
      "[65] loss: 5.569, val_loss: 13.703\n",
      "[66] loss: 5.411, val_loss: 13.679\n",
      "[67] loss: 5.653, val_loss: 13.528\n",
      "[68] loss: 5.390, val_loss: 13.224\n",
      "[69] loss: 6.044, val_loss: 13.843\n",
      "[70] loss: 6.052, val_loss: 13.350\n",
      "[71] loss: 6.307, val_loss: 13.392\n",
      "[72] loss: 5.938, val_loss: 13.991\n",
      "[73] loss: 5.547, val_loss: 13.096\n",
      "[74] loss: 6.965, val_loss: 13.328\n",
      "[75] loss: 5.498, val_loss: 14.515\n",
      "[76] loss: 7.759, val_loss: 13.287\n",
      "[77] loss: 6.660, val_loss: 13.219\n",
      "[78] loss: 6.672, val_loss: 13.561\n",
      "[79] loss: 5.643, val_loss: 13.628\n",
      "[80] loss: 5.599, val_loss: 13.499\n",
      "[81] loss: 5.937, val_loss: 13.559\n",
      "[82] loss: 5.360, val_loss: 13.767\n",
      "[83] loss: 5.638, val_loss: 13.326\n",
      "[84] loss: 5.506, val_loss: 13.535\n",
      "[85] loss: 5.132, val_loss: 13.866\n",
      "[86] loss: 5.322, val_loss: 13.323\n",
      "[87] loss: 5.309, val_loss: 13.678\n",
      "[88] loss: 5.179, val_loss: 13.631\n",
      "[89] loss: 4.999, val_loss: 13.532\n",
      "[90] loss: 4.975, val_loss: 13.773\n",
      "[91] loss: 4.918, val_loss: 13.476\n",
      "[92] loss: 5.292, val_loss: 13.961\n",
      "[93] loss: 5.254, val_loss: 13.549\n",
      "[94] loss: 4.943, val_loss: 13.652\n",
      "[95] loss: 4.991, val_loss: 13.653\n",
      "[96] loss: 4.860, val_loss: 13.614\n",
      "[97] loss: 4.979, val_loss: 13.897\n",
      "[98] loss: 4.987, val_loss: 13.627\n",
      "[99] loss: 4.923, val_loss: 14.239\n",
      "[100] loss: 4.815, val_loss: 13.840\n",
      "[101] loss: 4.724, val_loss: 13.940\n",
      "[102] loss: 4.897, val_loss: 13.858\n",
      "[103] loss: 4.830, val_loss: 14.443\n",
      "[104] loss: 5.031, val_loss: 14.080\n",
      "[105] loss: 4.927, val_loss: 13.662\n",
      "[106] loss: 5.010, val_loss: 14.436\n",
      "[107] loss: 4.976, val_loss: 14.055\n",
      "[108] loss: 4.845, val_loss: 14.077\n",
      "[109] loss: 4.673, val_loss: 14.522\n",
      "[110] loss: 4.959, val_loss: 13.782\n",
      "[111] loss: 5.343, val_loss: 14.057\n",
      "[112] loss: 4.908, val_loss: 14.014\n",
      "[113] loss: 4.782, val_loss: 14.189\n",
      "[114] loss: 4.735, val_loss: 14.113\n",
      "[115] loss: 4.585, val_loss: 13.936\n",
      "[116] loss: 4.644, val_loss: 14.194\n",
      "[117] loss: 4.582, val_loss: 13.935\n",
      "[118] loss: 4.584, val_loss: 14.790\n",
      "[119] loss: 5.505, val_loss: 13.598\n",
      "[120] loss: 5.968, val_loss: 13.696\n",
      "[121] loss: 4.773, val_loss: 14.870\n",
      "[122] loss: 6.635, val_loss: 13.635\n",
      "[123] loss: 5.556, val_loss: 13.772\n",
      "[124] loss: 5.030, val_loss: 14.527\n",
      "[125] loss: 5.541, val_loss: 13.499\n",
      "[126] loss: 5.327, val_loss: 13.603\n",
      "[127] loss: 4.650, val_loss: 14.777\n",
      "[128] loss: 5.744, val_loss: 13.824\n",
      "[129] loss: 5.302, val_loss: 13.778\n",
      "[130] loss: 4.848, val_loss: 14.460\n",
      "[131] loss: 5.186, val_loss: 13.655\n",
      "[132] loss: 4.904, val_loss: 13.978\n",
      "[133] loss: 4.562, val_loss: 14.142\n",
      "[134] loss: 4.373, val_loss: 13.955\n",
      "[135] loss: 4.562, val_loss: 14.444\n",
      "[136] loss: 4.402, val_loss: 14.016\n",
      "[137] loss: 4.426, val_loss: 14.385\n",
      "[138] loss: 4.529, val_loss: 13.475\n",
      "[139] loss: 4.927, val_loss: 14.283\n",
      "[140] loss: 4.385, val_loss: 13.808\n",
      "[141] loss: 4.847, val_loss: 13.882\n",
      "[142] loss: 4.417, val_loss: 14.205\n",
      "[143] loss: 4.254, val_loss: 13.764\n",
      "[144] loss: 4.651, val_loss: 14.325\n",
      "[145] loss: 4.372, val_loss: 13.850\n",
      "[146] loss: 4.566, val_loss: 14.619\n",
      "[147] loss: 4.437, val_loss: 13.831\n",
      "[148] loss: 4.591, val_loss: 14.365\n",
      "[149] loss: 4.193, val_loss: 14.251\n",
      "[150] loss: 4.054, val_loss: 13.846\n",
      "[151] loss: 4.227, val_loss: 14.648\n",
      "[152] loss: 4.199, val_loss: 14.009\n",
      "[153] loss: 4.275, val_loss: 14.422\n",
      "[154] loss: 4.168, val_loss: 14.341\n",
      "[155] loss: 4.235, val_loss: 14.575\n",
      "[156] loss: 4.175, val_loss: 13.828\n",
      "[157] loss: 4.163, val_loss: 14.823\n",
      "[158] loss: 4.555, val_loss: 13.764\n",
      "[159] loss: 4.956, val_loss: 14.258\n",
      "[160] loss: 4.964, val_loss: 13.745\n",
      "[161] loss: 4.126, val_loss: 13.853\n",
      "[162] loss: 4.123, val_loss: 14.283\n",
      "[163] loss: 4.290, val_loss: 13.652\n",
      "[164] loss: 5.803, val_loss: 14.323\n",
      "[165] loss: 3.946, val_loss: 14.808\n",
      "[166] loss: 4.936, val_loss: 13.642\n",
      "[167] loss: 5.494, val_loss: 13.726\n",
      "[168] loss: 4.595, val_loss: 14.455\n",
      "[169] loss: 4.531, val_loss: 13.670\n",
      "[170] loss: 4.539, val_loss: 13.925\n",
      "[171] loss: 4.062, val_loss: 14.060\n",
      "[172] loss: 3.916, val_loss: 14.266\n",
      "[173] loss: 3.760, val_loss: 14.099\n",
      "[174] loss: 3.895, val_loss: 14.545\n",
      "[175] loss: 4.112, val_loss: 13.769\n",
      "[176] loss: 4.780, val_loss: 14.663\n",
      "[177] loss: 4.813, val_loss: 14.174\n",
      "[178] loss: 4.509, val_loss: 14.331\n",
      "[179] loss: 3.862, val_loss: 14.673\n",
      "[180] loss: 4.313, val_loss: 14.135\n",
      "[181] loss: 4.197, val_loss: 14.506\n",
      "[182] loss: 3.887, val_loss: 14.219\n",
      "[183] loss: 3.654, val_loss: 14.657\n",
      "[184] loss: 3.629, val_loss: 14.375\n",
      "[185] loss: 3.682, val_loss: 14.663\n",
      "[186] loss: 3.401, val_loss: 14.780\n",
      "[187] loss: 3.864, val_loss: 14.393\n",
      "[188] loss: 3.500, val_loss: 15.141\n",
      "[189] loss: 3.889, val_loss: 14.129\n",
      "[190] loss: 5.328, val_loss: 14.561\n",
      "[191] loss: 4.918, val_loss: 14.605\n",
      "[192] loss: 4.095, val_loss: 13.897\n",
      "[193] loss: 4.571, val_loss: 14.727\n",
      "[194] loss: 4.992, val_loss: 14.453\n",
      "[195] loss: 4.187, val_loss: 14.481\n",
      "[196] loss: 3.848, val_loss: 14.772\n",
      "[197] loss: 4.061, val_loss: 13.810\n",
      "[198] loss: 5.242, val_loss: 14.537\n",
      "[199] loss: 4.125, val_loss: 14.615\n",
      "[200] loss: 3.684, val_loss: 13.719\n",
      "[1] loss: 18.851, val_loss: 19.657\n",
      "[2] loss: 16.899, val_loss: 17.494\n",
      "[3] loss: 14.023, val_loss: 13.974\n",
      "[4] loss: 10.382, val_loss: 10.154\n",
      "[5] loss: 9.860, val_loss: 11.380\n",
      "[6] loss: 10.100, val_loss: 10.343\n",
      "[7] loss: 9.340, val_loss: 11.448\n",
      "[8] loss: 9.490, val_loss: 12.087\n",
      "[9] loss: 9.409, val_loss: 11.802\n",
      "[10] loss: 9.190, val_loss: 10.883\n",
      "[11] loss: 9.062, val_loss: 10.670\n",
      "[12] loss: 9.056, val_loss: 10.829\n",
      "[13] loss: 9.055, val_loss: 10.943\n",
      "[14] loss: 8.873, val_loss: 11.299\n",
      "[15] loss: 8.793, val_loss: 11.672\n",
      "[16] loss: 8.735, val_loss: 11.632\n",
      "[17] loss: 8.632, val_loss: 11.671\n",
      "[18] loss: 8.538, val_loss: 11.958\n",
      "[19] loss: 8.443, val_loss: 12.168\n",
      "[20] loss: 8.349, val_loss: 12.377\n",
      "[21] loss: 8.251, val_loss: 12.653\n",
      "[22] loss: 8.224, val_loss: 12.758\n",
      "[23] loss: 8.057, val_loss: 12.836\n",
      "[24] loss: 8.140, val_loss: 13.036\n",
      "[25] loss: 7.990, val_loss: 13.223\n",
      "[26] loss: 7.991, val_loss: 13.229\n",
      "[27] loss: 7.880, val_loss: 13.355\n",
      "[28] loss: 7.807, val_loss: 13.439\n",
      "[29] loss: 7.855, val_loss: 13.362\n",
      "[30] loss: 7.743, val_loss: 13.260\n",
      "[31] loss: 7.727, val_loss: 13.337\n",
      "[32] loss: 7.561, val_loss: 13.419\n",
      "[33] loss: 7.592, val_loss: 13.310\n",
      "[34] loss: 7.472, val_loss: 13.368\n",
      "[35] loss: 7.413, val_loss: 13.422\n",
      "[36] loss: 7.300, val_loss: 13.344\n",
      "[37] loss: 7.426, val_loss: 13.436\n",
      "[38] loss: 7.496, val_loss: 12.982\n",
      "[39] loss: 7.220, val_loss: 12.988\n",
      "[40] loss: 7.158, val_loss: 13.382\n",
      "[41] loss: 7.758, val_loss: 12.869\n",
      "[42] loss: 7.399, val_loss: 12.715\n",
      "[43] loss: 7.055, val_loss: 12.773\n",
      "[44] loss: 7.037, val_loss: 12.925\n",
      "[45] loss: 6.834, val_loss: 13.096\n",
      "[46] loss: 6.901, val_loss: 12.925\n",
      "[47] loss: 7.106, val_loss: 12.481\n",
      "[48] loss: 6.707, val_loss: 12.509\n",
      "[49] loss: 6.633, val_loss: 12.814\n",
      "[50] loss: 6.459, val_loss: 13.152\n",
      "[51] loss: 6.509, val_loss: 13.273\n",
      "[52] loss: 6.550, val_loss: 13.289\n",
      "[53] loss: 6.348, val_loss: 12.875\n",
      "[54] loss: 6.494, val_loss: 13.017\n",
      "[55] loss: 6.538, val_loss: 13.038\n",
      "[56] loss: 6.962, val_loss: 12.622\n",
      "[57] loss: 6.340, val_loss: 13.134\n",
      "[58] loss: 6.325, val_loss: 13.621\n",
      "[59] loss: 6.411, val_loss: 13.815\n",
      "[60] loss: 6.357, val_loss: 13.439\n",
      "[61] loss: 6.357, val_loss: 12.934\n",
      "[62] loss: 6.028, val_loss: 13.298\n",
      "[63] loss: 5.910, val_loss: 13.752\n",
      "[64] loss: 6.430, val_loss: 13.685\n",
      "[65] loss: 6.325, val_loss: 13.336\n",
      "[66] loss: 6.034, val_loss: 13.164\n",
      "[67] loss: 5.747, val_loss: 13.248\n",
      "[68] loss: 5.972, val_loss: 13.964\n",
      "[69] loss: 5.842, val_loss: 14.462\n",
      "[70] loss: 6.323, val_loss: 14.039\n",
      "[71] loss: 6.287, val_loss: 13.315\n",
      "[72] loss: 5.774, val_loss: 13.120\n",
      "[73] loss: 5.837, val_loss: 13.988\n",
      "[74] loss: 6.216, val_loss: 13.739\n",
      "[75] loss: 5.770, val_loss: 13.555\n",
      "[76] loss: 5.773, val_loss: 14.172\n",
      "[77] loss: 6.330, val_loss: 13.669\n",
      "[78] loss: 5.423, val_loss: 13.608\n",
      "[79] loss: 5.812, val_loss: 14.379\n",
      "[80] loss: 5.891, val_loss: 14.106\n",
      "[81] loss: 5.472, val_loss: 14.025\n",
      "[82] loss: 5.232, val_loss: 13.789\n",
      "[83] loss: 5.346, val_loss: 14.224\n",
      "[84] loss: 5.096, val_loss: 14.504\n",
      "[85] loss: 5.112, val_loss: 14.770\n",
      "[86] loss: 5.124, val_loss: 14.672\n",
      "[87] loss: 5.432, val_loss: 15.556\n",
      "[88] loss: 6.929, val_loss: 14.976\n",
      "[89] loss: 5.702, val_loss: 14.450\n",
      "[90] loss: 6.396, val_loss: 15.104\n",
      "[91] loss: 6.940, val_loss: 15.172\n",
      "[92] loss: 6.506, val_loss: 14.152\n",
      "[93] loss: 5.517, val_loss: 14.118\n",
      "[94] loss: 5.422, val_loss: 14.599\n",
      "[95] loss: 5.144, val_loss: 14.508\n",
      "[96] loss: 4.997, val_loss: 14.637\n",
      "[97] loss: 4.841, val_loss: 14.933\n",
      "[98] loss: 5.205, val_loss: 15.033\n",
      "[99] loss: 4.784, val_loss: 15.107\n",
      "[100] loss: 4.889, val_loss: 14.728\n",
      "[101] loss: 5.570, val_loss: 15.489\n",
      "[102] loss: 6.040, val_loss: 15.016\n",
      "[103] loss: 4.824, val_loss: 14.504\n",
      "[104] loss: 5.577, val_loss: 15.479\n",
      "[105] loss: 6.135, val_loss: 15.419\n",
      "[106] loss: 5.387, val_loss: 14.491\n",
      "[107] loss: 6.014, val_loss: 14.973\n",
      "[108] loss: 5.506, val_loss: 15.233\n",
      "[109] loss: 5.382, val_loss: 14.357\n",
      "[110] loss: 5.587, val_loss: 14.755\n",
      "[111] loss: 4.889, val_loss: 15.314\n",
      "[112] loss: 4.861, val_loss: 14.532\n",
      "[113] loss: 5.142, val_loss: 14.982\n",
      "[114] loss: 4.676, val_loss: 15.117\n",
      "[115] loss: 4.583, val_loss: 14.897\n",
      "[116] loss: 4.549, val_loss: 15.506\n",
      "[117] loss: 4.986, val_loss: 14.621\n",
      "[118] loss: 4.820, val_loss: 15.152\n",
      "[119] loss: 4.997, val_loss: 14.765\n",
      "[120] loss: 4.541, val_loss: 14.703\n",
      "[121] loss: 4.400, val_loss: 15.225\n",
      "[122] loss: 4.428, val_loss: 14.813\n",
      "[123] loss: 4.460, val_loss: 15.442\n",
      "[124] loss: 4.667, val_loss: 14.858\n",
      "[125] loss: 4.500, val_loss: 15.204\n",
      "[126] loss: 4.492, val_loss: 14.809\n",
      "[127] loss: 4.674, val_loss: 15.691\n",
      "[128] loss: 4.811, val_loss: 15.244\n",
      "[129] loss: 4.655, val_loss: 15.518\n",
      "[130] loss: 4.438, val_loss: 15.217\n",
      "[131] loss: 4.186, val_loss: 15.252\n",
      "[132] loss: 4.090, val_loss: 15.270\n",
      "[133] loss: 4.069, val_loss: 15.206\n",
      "[134] loss: 4.039, val_loss: 14.920\n",
      "[135] loss: 4.180, val_loss: 15.099\n",
      "[136] loss: 4.076, val_loss: 15.117\n",
      "[137] loss: 3.956, val_loss: 15.956\n",
      "[138] loss: 4.445, val_loss: 15.806\n",
      "[139] loss: 4.604, val_loss: 16.062\n",
      "[140] loss: 4.847, val_loss: 15.506\n",
      "[141] loss: 4.426, val_loss: 15.740\n",
      "[142] loss: 4.412, val_loss: 15.719\n",
      "[143] loss: 3.938, val_loss: 15.766\n",
      "[144] loss: 3.963, val_loss: 15.605\n",
      "[145] loss: 3.937, val_loss: 15.421\n",
      "[146] loss: 3.833, val_loss: 15.569\n",
      "[147] loss: 3.773, val_loss: 15.828\n",
      "[148] loss: 4.343, val_loss: 15.440\n",
      "[149] loss: 4.407, val_loss: 16.560\n",
      "[150] loss: 6.248, val_loss: 15.744\n",
      "[151] loss: 4.002, val_loss: 15.160\n",
      "[152] loss: 5.576, val_loss: 15.641\n",
      "[153] loss: 5.221, val_loss: 15.792\n",
      "[154] loss: 4.623, val_loss: 15.501\n",
      "[155] loss: 4.320, val_loss: 16.133\n",
      "[156] loss: 4.912, val_loss: 15.707\n",
      "[157] loss: 3.969, val_loss: 15.458\n",
      "[158] loss: 3.988, val_loss: 15.706\n",
      "[159] loss: 4.258, val_loss: 15.127\n",
      "[160] loss: 4.246, val_loss: 15.676\n",
      "[161] loss: 4.689, val_loss: 15.717\n",
      "[162] loss: 3.956, val_loss: 15.576\n",
      "[163] loss: 3.795, val_loss: 15.868\n",
      "[164] loss: 3.592, val_loss: 15.805\n",
      "[165] loss: 3.721, val_loss: 16.070\n",
      "[166] loss: 3.675, val_loss: 15.642\n",
      "[167] loss: 3.919, val_loss: 16.270\n",
      "[168] loss: 4.510, val_loss: 15.837\n",
      "[169] loss: 4.402, val_loss: 16.399\n",
      "[170] loss: 4.034, val_loss: 16.066\n",
      "[171] loss: 3.437, val_loss: 15.849\n",
      "[172] loss: 3.372, val_loss: 15.603\n",
      "[173] loss: 3.513, val_loss: 15.921\n",
      "[174] loss: 3.307, val_loss: 16.157\n",
      "[175] loss: 3.327, val_loss: 16.145\n",
      "[176] loss: 3.405, val_loss: 16.061\n",
      "[177] loss: 3.426, val_loss: 15.907\n",
      "[178] loss: 3.267, val_loss: 15.678\n",
      "[179] loss: 3.348, val_loss: 15.908\n",
      "[180] loss: 3.332, val_loss: 16.340\n",
      "[181] loss: 3.353, val_loss: 15.693\n",
      "[182] loss: 3.567, val_loss: 16.249\n",
      "[183] loss: 5.520, val_loss: 15.668\n",
      "[184] loss: 4.170, val_loss: 15.727\n",
      "[185] loss: 3.677, val_loss: 15.346\n",
      "[186] loss: 3.411, val_loss: 16.003\n",
      "[187] loss: 4.218, val_loss: 15.689\n",
      "[188] loss: 3.958, val_loss: 16.172\n",
      "[189] loss: 4.184, val_loss: 15.757\n",
      "[190] loss: 3.395, val_loss: 16.088\n",
      "[191] loss: 3.369, val_loss: 15.424\n",
      "[192] loss: 3.585, val_loss: 16.079\n",
      "[193] loss: 4.171, val_loss: 15.597\n",
      "[194] loss: 4.141, val_loss: 16.205\n",
      "[195] loss: 3.771, val_loss: 16.030\n",
      "[196] loss: 3.327, val_loss: 16.146\n",
      "[197] loss: 3.274, val_loss: 15.679\n",
      "[198] loss: 3.326, val_loss: 16.076\n",
      "[199] loss: 3.774, val_loss: 15.550\n",
      "[200] loss: 4.511, val_loss: 15.993\n",
      "[1] loss: 19.450, val_loss: 17.765\n",
      "[2] loss: 18.169, val_loss: 15.613\n",
      "[3] loss: 16.235, val_loss: 12.047\n",
      "[4] loss: 12.774, val_loss: 9.863\n",
      "[5] loss: 9.754, val_loss: 13.450\n",
      "[6] loss: 11.455, val_loss: 11.353\n",
      "[7] loss: 9.626, val_loss: 10.001\n",
      "[8] loss: 9.746, val_loss: 9.902\n",
      "[9] loss: 10.435, val_loss: 9.941\n",
      "[10] loss: 10.312, val_loss: 9.994\n",
      "[11] loss: 9.562, val_loss: 10.250\n",
      "[12] loss: 9.142, val_loss: 11.212\n",
      "[13] loss: 9.528, val_loss: 11.054\n",
      "[14] loss: 9.302, val_loss: 10.571\n",
      "[15] loss: 9.108, val_loss: 10.315\n",
      "[16] loss: 9.159, val_loss: 10.303\n",
      "[17] loss: 9.114, val_loss: 10.413\n",
      "[18] loss: 8.907, val_loss: 10.570\n",
      "[19] loss: 8.786, val_loss: 10.860\n",
      "[20] loss: 8.836, val_loss: 10.589\n",
      "[21] loss: 8.648, val_loss: 10.524\n",
      "[22] loss: 8.618, val_loss: 10.550\n",
      "[23] loss: 8.635, val_loss: 10.622\n",
      "[24] loss: 8.458, val_loss: 10.664\n",
      "[25] loss: 8.440, val_loss: 10.658\n",
      "[26] loss: 8.351, val_loss: 10.691\n",
      "[27] loss: 8.272, val_loss: 10.696\n",
      "[28] loss: 8.212, val_loss: 10.796\n",
      "[29] loss: 8.173, val_loss: 10.814\n",
      "[30] loss: 8.186, val_loss: 10.698\n",
      "[31] loss: 8.132, val_loss: 10.861\n",
      "[32] loss: 8.274, val_loss: 10.754\n",
      "[33] loss: 8.106, val_loss: 10.605\n",
      "[34] loss: 8.000, val_loss: 10.656\n",
      "[35] loss: 7.870, val_loss: 10.642\n",
      "[36] loss: 7.869, val_loss: 10.459\n",
      "[37] loss: 7.938, val_loss: 10.475\n",
      "[38] loss: 7.806, val_loss: 10.471\n",
      "[39] loss: 7.750, val_loss: 10.431\n",
      "[40] loss: 7.678, val_loss: 10.427\n",
      "[41] loss: 7.679, val_loss: 10.397\n",
      "[42] loss: 7.604, val_loss: 10.384\n",
      "[43] loss: 7.612, val_loss: 10.317\n",
      "[44] loss: 7.527, val_loss: 10.390\n",
      "[45] loss: 7.603, val_loss: 10.394\n",
      "[46] loss: 7.494, val_loss: 10.326\n",
      "[47] loss: 7.444, val_loss: 10.422\n",
      "[48] loss: 7.327, val_loss: 10.549\n",
      "[49] loss: 7.315, val_loss: 10.361\n",
      "[50] loss: 7.295, val_loss: 10.542\n",
      "[51] loss: 7.310, val_loss: 10.300\n",
      "[52] loss: 7.233, val_loss: 10.387\n",
      "[53] loss: 7.390, val_loss: 10.241\n",
      "[54] loss: 7.153, val_loss: 10.290\n",
      "[55] loss: 7.038, val_loss: 10.312\n",
      "[56] loss: 7.061, val_loss: 10.253\n",
      "[57] loss: 7.083, val_loss: 10.497\n",
      "[58] loss: 7.753, val_loss: 10.174\n",
      "[59] loss: 7.124, val_loss: 10.180\n",
      "[60] loss: 6.968, val_loss: 10.350\n",
      "[61] loss: 7.261, val_loss: 10.361\n",
      "[62] loss: 6.904, val_loss: 10.242\n",
      "[63] loss: 6.770, val_loss: 10.217\n",
      "[64] loss: 6.787, val_loss: 10.233\n",
      "[65] loss: 6.659, val_loss: 10.286\n",
      "[66] loss: 6.773, val_loss: 10.337\n",
      "[67] loss: 6.723, val_loss: 10.342\n",
      "[68] loss: 6.571, val_loss: 10.313\n",
      "[69] loss: 6.456, val_loss: 10.497\n",
      "[70] loss: 7.081, val_loss: 10.543\n",
      "[71] loss: 6.748, val_loss: 10.481\n",
      "[72] loss: 6.550, val_loss: 10.353\n",
      "[73] loss: 6.443, val_loss: 10.346\n",
      "[74] loss: 6.824, val_loss: 10.386\n",
      "[75] loss: 6.975, val_loss: 10.413\n",
      "[76] loss: 6.357, val_loss: 10.445\n",
      "[77] loss: 6.470, val_loss: 10.453\n",
      "[78] loss: 6.499, val_loss: 10.518\n",
      "[79] loss: 6.587, val_loss: 10.505\n",
      "[80] loss: 6.650, val_loss: 10.452\n",
      "[81] loss: 6.356, val_loss: 10.387\n",
      "[82] loss: 6.098, val_loss: 10.408\n",
      "[83] loss: 6.512, val_loss: 10.459\n",
      "[84] loss: 6.596, val_loss: 10.354\n",
      "[85] loss: 6.303, val_loss: 10.391\n",
      "[86] loss: 5.880, val_loss: 10.406\n",
      "[87] loss: 6.028, val_loss: 10.498\n",
      "[88] loss: 6.272, val_loss: 10.343\n",
      "[89] loss: 5.895, val_loss: 10.366\n",
      "[90] loss: 5.775, val_loss: 10.619\n",
      "[91] loss: 5.651, val_loss: 10.623\n",
      "[92] loss: 5.641, val_loss: 10.641\n",
      "[93] loss: 5.641, val_loss: 10.401\n",
      "[94] loss: 5.712, val_loss: 10.489\n",
      "[95] loss: 5.510, val_loss: 10.592\n",
      "[96] loss: 5.540, val_loss: 10.990\n",
      "[97] loss: 5.901, val_loss: 10.797\n",
      "[98] loss: 5.869, val_loss: 11.067\n",
      "[99] loss: 6.153, val_loss: 10.912\n",
      "[100] loss: 5.940, val_loss: 11.007\n",
      "[101] loss: 5.684, val_loss: 10.846\n",
      "[102] loss: 5.538, val_loss: 11.204\n",
      "[103] loss: 5.556, val_loss: 11.062\n",
      "[104] loss: 5.495, val_loss: 10.980\n",
      "[105] loss: 5.462, val_loss: 10.895\n",
      "[106] loss: 5.394, val_loss: 10.967\n",
      "[107] loss: 5.182, val_loss: 11.435\n",
      "[108] loss: 5.605, val_loss: 11.105\n",
      "[109] loss: 5.823, val_loss: 11.411\n",
      "[110] loss: 5.756, val_loss: 10.740\n",
      "[111] loss: 5.709, val_loss: 11.051\n",
      "[112] loss: 5.236, val_loss: 10.907\n",
      "[113] loss: 4.998, val_loss: 11.403\n",
      "[114] loss: 4.922, val_loss: 11.101\n",
      "[115] loss: 5.193, val_loss: 11.476\n",
      "[116] loss: 5.301, val_loss: 11.051\n",
      "[117] loss: 5.092, val_loss: 11.690\n",
      "[118] loss: 6.306, val_loss: 11.115\n",
      "[119] loss: 5.179, val_loss: 11.039\n",
      "[120] loss: 4.937, val_loss: 11.777\n",
      "[121] loss: 5.692, val_loss: 10.992\n",
      "[122] loss: 5.129, val_loss: 11.501\n",
      "[123] loss: 5.240, val_loss: 11.297\n",
      "[124] loss: 4.844, val_loss: 11.511\n",
      "[125] loss: 4.806, val_loss: 11.613\n",
      "[126] loss: 4.721, val_loss: 11.104\n",
      "[127] loss: 5.397, val_loss: 11.835\n",
      "[128] loss: 6.396, val_loss: 11.283\n",
      "[129] loss: 5.179, val_loss: 11.055\n",
      "[130] loss: 5.092, val_loss: 11.608\n",
      "[131] loss: 5.019, val_loss: 11.261\n",
      "[132] loss: 4.641, val_loss: 11.578\n",
      "[133] loss: 4.770, val_loss: 11.485\n",
      "[134] loss: 4.968, val_loss: 12.423\n",
      "[135] loss: 6.662, val_loss: 12.242\n",
      "[136] loss: 5.767, val_loss: 11.805\n",
      "[137] loss: 5.526, val_loss: 11.906\n",
      "[138] loss: 6.636, val_loss: 11.604\n",
      "[139] loss: 4.950, val_loss: 11.857\n",
      "[140] loss: 7.683, val_loss: 11.193\n",
      "[141] loss: 4.662, val_loss: 11.861\n",
      "[142] loss: 5.812, val_loss: 11.549\n",
      "[143] loss: 5.001, val_loss: 11.617\n",
      "[144] loss: 4.825, val_loss: 12.024\n",
      "[145] loss: 4.809, val_loss: 11.206\n",
      "[146] loss: 5.045, val_loss: 11.507\n",
      "[147] loss: 4.894, val_loss: 11.603\n",
      "[148] loss: 4.356, val_loss: 11.395\n",
      "[149] loss: 4.557, val_loss: 12.021\n",
      "[150] loss: 4.637, val_loss: 11.351\n",
      "[151] loss: 4.864, val_loss: 11.755\n",
      "[152] loss: 4.740, val_loss: 11.442\n",
      "[153] loss: 4.558, val_loss: 11.550\n",
      "[154] loss: 4.510, val_loss: 12.250\n",
      "[155] loss: 4.836, val_loss: 11.815\n",
      "[156] loss: 4.944, val_loss: 12.077\n",
      "[157] loss: 5.004, val_loss: 11.673\n",
      "[158] loss: 4.266, val_loss: 11.673\n",
      "[159] loss: 4.790, val_loss: 12.351\n",
      "[160] loss: 5.543, val_loss: 12.165\n",
      "[161] loss: 4.597, val_loss: 12.018\n",
      "[162] loss: 4.295, val_loss: 12.375\n",
      "[163] loss: 4.484, val_loss: 11.506\n",
      "[164] loss: 4.978, val_loss: 11.891\n",
      "[165] loss: 4.809, val_loss: 11.733\n",
      "[166] loss: 4.090, val_loss: 11.922\n",
      "[167] loss: 4.309, val_loss: 12.513\n",
      "[168] loss: 5.260, val_loss: 11.975\n",
      "[169] loss: 4.677, val_loss: 12.225\n",
      "[170] loss: 4.310, val_loss: 11.690\n",
      "[171] loss: 4.191, val_loss: 11.772\n",
      "[172] loss: 3.763, val_loss: 12.282\n",
      "[173] loss: 4.601, val_loss: 11.926\n",
      "[174] loss: 4.592, val_loss: 12.491\n",
      "[175] loss: 4.935, val_loss: 12.215\n",
      "[176] loss: 4.448, val_loss: 12.046\n",
      "[177] loss: 4.206, val_loss: 12.259\n",
      "[178] loss: 3.861, val_loss: 11.698\n",
      "[179] loss: 4.282, val_loss: 12.366\n",
      "[180] loss: 4.092, val_loss: 11.793\n",
      "[181] loss: 3.825, val_loss: 12.606\n",
      "[182] loss: 4.097, val_loss: 12.276\n",
      "[183] loss: 3.993, val_loss: 12.882\n",
      "[184] loss: 4.370, val_loss: 12.138\n",
      "[185] loss: 3.817, val_loss: 12.615\n",
      "[186] loss: 3.951, val_loss: 12.274\n",
      "[187] loss: 3.675, val_loss: 12.422\n",
      "[188] loss: 3.927, val_loss: 11.993\n",
      "[189] loss: 4.074, val_loss: 12.648\n",
      "[190] loss: 3.470, val_loss: 13.065\n",
      "[191] loss: 3.511, val_loss: 13.050\n",
      "[192] loss: 3.431, val_loss: 12.976\n",
      "[193] loss: 3.795, val_loss: 12.651\n",
      "[194] loss: 3.635, val_loss: 13.054\n",
      "[195] loss: 3.563, val_loss: 12.682\n",
      "[196] loss: 3.488, val_loss: 13.144\n",
      "[197] loss: 5.055, val_loss: 12.580\n",
      "[198] loss: 3.528, val_loss: 12.896\n",
      "[199] loss: 3.869, val_loss: 12.416\n",
      "[200] loss: 3.971, val_loss: 13.439\n",
      "[1] loss: 19.509, val_loss: 15.254\n",
      "[2] loss: 17.200, val_loss: 12.821\n",
      "[3] loss: 13.422, val_loss: 10.269\n",
      "[4] loss: 10.391, val_loss: 12.090\n",
      "[5] loss: 11.431, val_loss: 11.322\n",
      "[6] loss: 10.176, val_loss: 10.087\n",
      "[7] loss: 9.669, val_loss: 10.167\n",
      "[8] loss: 10.081, val_loss: 10.198\n",
      "[9] loss: 9.979, val_loss: 10.058\n",
      "[10] loss: 9.559, val_loss: 10.141\n",
      "[11] loss: 9.106, val_loss: 10.643\n",
      "[12] loss: 9.618, val_loss: 10.687\n",
      "[13] loss: 9.250, val_loss: 10.150\n",
      "[14] loss: 9.015, val_loss: 10.017\n",
      "[15] loss: 9.225, val_loss: 9.958\n",
      "[16] loss: 9.205, val_loss: 10.029\n",
      "[17] loss: 8.957, val_loss: 10.292\n",
      "[18] loss: 8.950, val_loss: 10.729\n",
      "[19] loss: 8.887, val_loss: 10.414\n",
      "[20] loss: 8.732, val_loss: 10.267\n",
      "[21] loss: 8.680, val_loss: 10.347\n",
      "[22] loss: 8.633, val_loss: 10.152\n",
      "[23] loss: 8.572, val_loss: 10.088\n",
      "[24] loss: 8.548, val_loss: 9.959\n",
      "[25] loss: 8.496, val_loss: 9.883\n",
      "[26] loss: 8.480, val_loss: 10.058\n",
      "[27] loss: 8.440, val_loss: 10.139\n",
      "[28] loss: 8.385, val_loss: 9.991\n",
      "[29] loss: 8.380, val_loss: 9.810\n",
      "[30] loss: 8.315, val_loss: 9.805\n",
      "[31] loss: 8.254, val_loss: 9.825\n",
      "[32] loss: 8.208, val_loss: 9.719\n",
      "[33] loss: 8.128, val_loss: 9.703\n",
      "[34] loss: 8.107, val_loss: 9.748\n",
      "[35] loss: 8.070, val_loss: 9.700\n",
      "[36] loss: 8.029, val_loss: 9.533\n",
      "[37] loss: 8.125, val_loss: 9.542\n",
      "[38] loss: 8.109, val_loss: 9.423\n",
      "[39] loss: 7.873, val_loss: 9.397\n",
      "[40] loss: 7.830, val_loss: 9.399\n",
      "[41] loss: 7.755, val_loss: 9.321\n",
      "[42] loss: 7.838, val_loss: 9.408\n",
      "[43] loss: 7.883, val_loss: 9.385\n",
      "[44] loss: 7.805, val_loss: 9.176\n",
      "[45] loss: 7.912, val_loss: 9.274\n",
      "[46] loss: 7.784, val_loss: 9.607\n",
      "[47] loss: 8.120, val_loss: 9.121\n",
      "[48] loss: 7.816, val_loss: 9.052\n",
      "[49] loss: 7.633, val_loss: 9.194\n",
      "[50] loss: 7.661, val_loss: 8.997\n",
      "[51] loss: 7.586, val_loss: 8.954\n",
      "[52] loss: 7.547, val_loss: 9.089\n",
      "[53] loss: 7.739, val_loss: 8.772\n",
      "[54] loss: 7.716, val_loss: 8.831\n",
      "[55] loss: 7.501, val_loss: 8.936\n",
      "[56] loss: 7.552, val_loss: 8.700\n",
      "[57] loss: 7.573, val_loss: 8.586\n",
      "[58] loss: 7.431, val_loss: 8.708\n",
      "[59] loss: 7.369, val_loss: 8.662\n",
      "[60] loss: 7.454, val_loss: 8.725\n",
      "[61] loss: 7.486, val_loss: 8.461\n",
      "[62] loss: 7.593, val_loss: 8.393\n",
      "[63] loss: 7.257, val_loss: 8.533\n",
      "[64] loss: 7.544, val_loss: 8.245\n",
      "[65] loss: 7.306, val_loss: 8.180\n",
      "[66] loss: 7.100, val_loss: 8.469\n",
      "[67] loss: 7.212, val_loss: 8.211\n",
      "[68] loss: 7.474, val_loss: 8.091\n",
      "[69] loss: 7.106, val_loss: 8.012\n",
      "[70] loss: 7.007, val_loss: 8.092\n",
      "[71] loss: 7.388, val_loss: 7.915\n",
      "[72] loss: 6.897, val_loss: 8.023\n",
      "[73] loss: 7.001, val_loss: 7.771\n",
      "[74] loss: 7.011, val_loss: 7.769\n",
      "[75] loss: 6.896, val_loss: 7.898\n",
      "[76] loss: 6.780, val_loss: 7.931\n",
      "[77] loss: 7.114, val_loss: 7.820\n",
      "[78] loss: 6.640, val_loss: 8.048\n",
      "[79] loss: 7.055, val_loss: 7.708\n",
      "[80] loss: 7.318, val_loss: 7.561\n",
      "[81] loss: 6.845, val_loss: 8.286\n",
      "[82] loss: 7.184, val_loss: 7.591\n",
      "[83] loss: 6.932, val_loss: 7.513\n",
      "[84] loss: 6.668, val_loss: 7.550\n",
      "[85] loss: 6.615, val_loss: 7.198\n",
      "[86] loss: 6.512, val_loss: 7.726\n",
      "[87] loss: 6.739, val_loss: 7.340\n",
      "[88] loss: 6.589, val_loss: 7.608\n",
      "[89] loss: 6.452, val_loss: 7.580\n",
      "[90] loss: 6.245, val_loss: 7.498\n",
      "[91] loss: 6.244, val_loss: 7.263\n",
      "[92] loss: 6.178, val_loss: 7.871\n",
      "[93] loss: 6.612, val_loss: 7.583\n",
      "[94] loss: 6.469, val_loss: 8.407\n",
      "[95] loss: 6.958, val_loss: 7.350\n",
      "[96] loss: 6.635, val_loss: 7.248\n",
      "[97] loss: 6.115, val_loss: 7.604\n",
      "[98] loss: 6.236, val_loss: 7.441\n",
      "[99] loss: 7.262, val_loss: 7.647\n",
      "[100] loss: 6.910, val_loss: 8.258\n",
      "[101] loss: 6.564, val_loss: 7.510\n",
      "[102] loss: 7.984, val_loss: 7.734\n",
      "[103] loss: 7.348, val_loss: 7.869\n",
      "[104] loss: 7.242, val_loss: 7.931\n",
      "[105] loss: 6.175, val_loss: 7.538\n",
      "[106] loss: 7.223, val_loss: 7.421\n",
      "[107] loss: 6.165, val_loss: 9.430\n",
      "[108] loss: 7.741, val_loss: 7.396\n",
      "[109] loss: 6.130, val_loss: 7.254\n",
      "[110] loss: 6.478, val_loss: 7.608\n",
      "[111] loss: 6.008, val_loss: 7.483\n",
      "[112] loss: 5.801, val_loss: 7.174\n",
      "[113] loss: 5.895, val_loss: 7.987\n",
      "[114] loss: 6.250, val_loss: 7.487\n",
      "[115] loss: 6.827, val_loss: 7.515\n",
      "[116] loss: 6.166, val_loss: 9.685\n",
      "[117] loss: 7.556, val_loss: 7.414\n",
      "[118] loss: 6.234, val_loss: 7.532\n",
      "[119] loss: 6.091, val_loss: 7.783\n",
      "[120] loss: 6.113, val_loss: 7.485\n",
      "[121] loss: 5.679, val_loss: 7.439\n",
      "[122] loss: 5.675, val_loss: 8.018\n",
      "[123] loss: 5.730, val_loss: 7.449\n",
      "[124] loss: 5.882, val_loss: 8.024\n",
      "[125] loss: 5.839, val_loss: 7.343\n",
      "[126] loss: 5.740, val_loss: 7.741\n",
      "[127] loss: 5.521, val_loss: 7.272\n",
      "[128] loss: 5.387, val_loss: 7.590\n",
      "[129] loss: 5.227, val_loss: 8.028\n",
      "[130] loss: 5.287, val_loss: 8.141\n",
      "[131] loss: 5.385, val_loss: 7.804\n",
      "[132] loss: 6.436, val_loss: 7.462\n",
      "[133] loss: 5.452, val_loss: 8.417\n",
      "[134] loss: 5.285, val_loss: 7.966\n",
      "[135] loss: 5.388, val_loss: 9.586\n",
      "[136] loss: 5.946, val_loss: 7.686\n",
      "[137] loss: 5.667, val_loss: 7.742\n",
      "[138] loss: 5.048, val_loss: 7.896\n",
      "[139] loss: 4.893, val_loss: 7.613\n",
      "[140] loss: 5.190, val_loss: 7.939\n",
      "[141] loss: 5.134, val_loss: 7.840\n",
      "[142] loss: 5.219, val_loss: 9.101\n",
      "[143] loss: 5.642, val_loss: 7.820\n",
      "[144] loss: 6.460, val_loss: 7.930\n",
      "[145] loss: 4.738, val_loss: 8.488\n",
      "[146] loss: 4.971, val_loss: 8.145\n",
      "[147] loss: 6.025, val_loss: 7.778\n",
      "[148] loss: 5.010, val_loss: 8.540\n",
      "[149] loss: 5.640, val_loss: 8.067\n",
      "[150] loss: 6.606, val_loss: 7.964\n",
      "[151] loss: 5.348, val_loss: 8.986\n",
      "[152] loss: 5.951, val_loss: 7.585\n",
      "[153] loss: 5.575, val_loss: 7.386\n",
      "[154] loss: 5.189, val_loss: 9.056\n",
      "[155] loss: 5.290, val_loss: 7.650\n",
      "[156] loss: 5.402, val_loss: 8.145\n",
      "[157] loss: 4.827, val_loss: 7.624\n",
      "[158] loss: 4.521, val_loss: 7.243\n",
      "[159] loss: 4.492, val_loss: 8.151\n",
      "[160] loss: 4.441, val_loss: 7.577\n",
      "[161] loss: 5.517, val_loss: 8.158\n",
      "[162] loss: 5.321, val_loss: 7.949\n",
      "[163] loss: 4.511, val_loss: 7.655\n",
      "[164] loss: 4.347, val_loss: 7.779\n",
      "[165] loss: 4.299, val_loss: 7.263\n",
      "[166] loss: 5.059, val_loss: 7.843\n",
      "[167] loss: 5.231, val_loss: 7.004\n",
      "[168] loss: 4.630, val_loss: 7.704\n",
      "[169] loss: 4.092, val_loss: 8.002\n",
      "[170] loss: 4.385, val_loss: 7.161\n",
      "[171] loss: 4.539, val_loss: 9.755\n",
      "[172] loss: 5.559, val_loss: 7.485\n",
      "[173] loss: 5.808, val_loss: 7.333\n",
      "[174] loss: 4.254, val_loss: 8.984\n",
      "[175] loss: 4.740, val_loss: 7.951\n",
      "[176] loss: 6.119, val_loss: 7.169\n",
      "[177] loss: 4.546, val_loss: 9.526\n",
      "[178] loss: 5.265, val_loss: 8.019\n",
      "[179] loss: 6.005, val_loss: 7.460\n",
      "[180] loss: 4.281, val_loss: 9.366\n",
      "[181] loss: 4.882, val_loss: 7.831\n",
      "[182] loss: 4.666, val_loss: 8.032\n",
      "[183] loss: 4.234, val_loss: 7.684\n",
      "[184] loss: 3.920, val_loss: 7.468\n",
      "[185] loss: 3.941, val_loss: 7.563\n",
      "[186] loss: 3.822, val_loss: 7.626\n",
      "[187] loss: 4.152, val_loss: 7.891\n",
      "[188] loss: 4.201, val_loss: 8.044\n",
      "[189] loss: 4.632, val_loss: 8.437\n",
      "[190] loss: 4.634, val_loss: 7.465\n",
      "[191] loss: 3.808, val_loss: 7.942\n",
      "[192] loss: 3.703, val_loss: 8.292\n",
      "[193] loss: 3.865, val_loss: 8.066\n",
      "[194] loss: 4.612, val_loss: 10.435\n",
      "[195] loss: 5.991, val_loss: 7.410\n",
      "[196] loss: 5.422, val_loss: 7.187\n",
      "[197] loss: 4.072, val_loss: 9.596\n",
      "[198] loss: 5.379, val_loss: 7.569\n",
      "[199] loss: 4.664, val_loss: 7.546\n",
      "[200] loss: 4.169, val_loss: 9.667\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils.data import ConcatDataset\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "sys.path.append('../')\n",
    "from models import VAE, SameTPred\n",
    "from utils import BrainGraphDataset, project_root\n",
    "import json\n",
    "import copy\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lr = 0.001\n",
    "batch_size = 32\n",
    "\n",
    "# define the optimizer and the loss function\n",
    "\n",
    "criterion = nn.L1Loss(reduction='sum')\n",
    "\n",
    "root = project_root()\n",
    "\n",
    "dataroot = 'fc_matrices/psilo_ica_100_before'\n",
    "annotations = 'annotations-before.csv'\n",
    "before_dataset = BrainGraphDataset(img_dir=os.path.join(root, dataroot),\n",
    "                            annotations_file=os.path.join(root, annotations),\n",
    "                            transform=None, extra_data=None, setting='upper_triangular')\n",
    "\n",
    "dataroot = 'fc_matrices/psilo_ica_100_after'\n",
    "annotations = 'annotations-after.csv'\n",
    "after_dataset = BrainGraphDataset(img_dir=os.path.join(root, dataroot),\n",
    "                            annotations_file=os.path.join(root, annotations),\n",
    "                            transform=None, extra_data=None, setting='upper_triangular')\n",
    "\n",
    "dataset = ConcatDataset([before_dataset, after_dataset])\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Create empty lists to store train and validation loaders\n",
    "train_loaders = []\n",
    "val_loaders = []\n",
    "\n",
    "torch.manual_seed(0)\n",
    "for train_index, val_index in kf.split(dataset):\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_set = torch.utils.data.Subset(dataset, train_index)\n",
    "    val_set = torch.utils.data.Subset(dataset, val_index)\n",
    "\n",
    "    # Define the dataloaders for the current fold\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Append the loaders to the respective lists\n",
    "    train_loaders.append(train_loader)\n",
    "    val_loaders.append(val_loader)\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "# Dictionary to store training and validation curves\n",
    "curves = {}\n",
    "\n",
    "best_set = [None] * 5\n",
    "\n",
    "input_dim = 4950\n",
    "for dropout in [0]:\n",
    "    for t, train_loader in enumerate(train_loaders):\n",
    "        val_loader = val_loaders[t]\n",
    "    \n",
    "        vae = VAE(4950, [128] * 2, 64).to(device)  # move model to device\n",
    "        vae.load_state_dict(torch.load(os.path.join(root, 'vae_weights/vae_dropout_psilo_ica_before_0.pt'), map_location=device))\n",
    "        vae = vae.to(device)\n",
    "\n",
    "        model = SameTPred(64, 256, dropout=dropout)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        # Convert the MLP to the device\n",
    "        model.to(device)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        best_state = None\n",
    "\n",
    "        # Lists to store training and validation losses\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        best_pass = None\n",
    "        # train the MLP on the new dataset\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for i, data in enumerate(train_loader, 0):\n",
    "                # get the inputs\n",
    "                graphs, labels = data\n",
    "\n",
    "                graphs = graphs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                _, _, _, z = vae(graphs.view(-1, input_dim))\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                preds = model(z)\n",
    "\n",
    "                # calculate the loss and backpropagate\n",
    "                loss = model.loss(preds, labels.view(preds.shape))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Validation check\n",
    "            val_loss = 0.0\n",
    "            val_label = []\n",
    "            val_output = []\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    graphs, labels = data\n",
    "\n",
    "                    graphs = graphs.to(device)\n",
    "                    labels = labels.to(device).float()\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    _, _, _, z = vae(graphs.view(-1, input_dim))\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    preds = model(z)\n",
    "\n",
    "                    val_label.extend(labels.flatten().tolist())\n",
    "                    val_output.extend(preds.flatten().tolist())\n",
    "\n",
    "                    val_loss += criterion(preds, labels.view(preds.shape)).item()\n",
    "            val_loss /= len(val_set)\n",
    "\n",
    "            # Save the best model so far\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_state = (copy.deepcopy(model.state_dict()), copy.deepcopy(vae.state_dict()))\n",
    "                best_pass = (val_label, val_output)\n",
    "\n",
    "            # Print statistics and perform testing every 5 epochs\n",
    "            print('[%d] loss: %.3f, val_loss: %.3f' % (epoch + 1, running_loss / (len(train_set)), val_loss))\n",
    "\n",
    "            train_losses.append(running_loss / (len(train_set)))\n",
    "            val_losses.append(val_loss)\n",
    "        best_set[t] = best_pass\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01539561786230581\n",
      "PearsonRResult(statistic=0.32796624502507143, pvalue=0.0023227007225613615)\n",
      "8.57415236745562\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "true = []\n",
    "pred = []\n",
    "\n",
    "for fold in best_set:\n",
    "    true.extend(fold[0])\n",
    "    pred.extend(fold[1])\n",
    "\n",
    "print(r2_score(true, pred))\n",
    "print(pearsonr(true, pred))\n",
    "print(mean_absolute_error(true, pred))\n",
    "\n",
    "# Generate jittered data\n",
    "jitter = 0.01  # Adjust the jittering amount as needed\n",
    "true_jittered = np.array(true) + np.random.uniform(low=-jitter, high=jitter, size=len(true))\n",
    "pred_jittered = np.array(pred) + np.random.uniform(low=-jitter, high=jitter, size=len(pred))\n",
    "\n",
    "plt.scatter(true_jittered, pred_jittered, alpha=0.7, color='red', marker='x')\n",
    "\n",
    "min_val = min(min(true), min(pred))\n",
    "max_val = max(max(true), max(pred))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--', label='X=Y')\n",
    "\n",
    "plt.xlabel('True BDI')\n",
    "plt.ylabel('Predicted BDI')\n",
    "plt.title('Same T Prediction (combined)')\n",
    "plt.legend()\n",
    "plt.savefig('same_t_pred.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Specify the filename for the CSV file\n",
    "filename = 'same-t-pred-vae.csv'\n",
    "\n",
    "# Create a list of rows with headers\n",
    "rows = [['true_post_bdi', 'predicted_post_bdi']]\n",
    "for true, pred in zip(total_true, total_pred):\n",
    "    rows.append([true, pred])\n",
    "\n",
    "import csv\n",
    "\n",
    "# Write the rows to the CSV file\n",
    "with open(filename, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
